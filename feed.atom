<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<id>http://blog.peterritchie.com/</id>
	<title>Peter Ritchie's Blog</title>
	<link rel="self" href="http://blog.peterritchie.com/" />
	<rights>2023</rights>
	<updated>2023-06-15T18:32:30Z</updated>
	<subtitle>Peter Ritchie</subtitle>
	<entry>
		<id>http://blog.peterritchie.com/posts/http-and-etag-header-fields</id>
		<title>HTTP and ETag Header Fields</title>
		<link href="http://blog.peterritchie.com/posts/http-and-etag-header-fields" />
		<updated>2023-06-15T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="../assets/accidental-overwrite.jpg" class="img-fluid" alt="A stuffed tiger corrupted appearance due to accidental overwrite" /&gt;&lt;/p&gt;
&lt;p&gt;Update: corrected mention of &lt;code&gt;412&lt;/code&gt; in the context of &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;If-Modified-Since&lt;/code&gt; to &lt;code&gt;304&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Over the last four-plus years, I have been almost exclusively working on some sort of *-as-a-Service (*aaS)—for example, Mortgage Origination as a Service, Insurance Claims as a Service. I always see a couple of things when implementing Web (HTTP) services: the &lt;em&gt;reinvention of the wheel&lt;/em&gt; and recognizing the problem ETags solves after publishing a specification (sometimes both).&lt;/p&gt;
&lt;p&gt;With *aaS as a Web API, the intention is to have multiple API clients providing access to representations of shared resources. Early in projects like this involves an initial (single) client, so the chances of a client having a stale resource representation are slim. When another client starts to use the API and an update gets accidentally overwritten, things get needlessly complicated.&lt;/p&gt;
&lt;p&gt;I've seen teams address this problem in a number of ways, often involving a date-time stamp. With multiple clients on an API, scalability is an issue, and a date-time stamp can mean different things to different servers (as we'll see below). You need a single authority for a resource's last modified date-time to avoid exchanging one problem for another. See &lt;a href="https://datatracker.ietf.org/doc/html/rfc7232#section-2.2.2"&gt;Last-Modified/Comparison&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;The creators of HTTP encountered this issue and added features to HTTP to deal with this (I assume that's why they added these features). I don't know when these features were devised, but they proposed them in 1997. So, they've been in the wild for at least 25 years with the entire web as a test bed. So, many brilliant people either created or scrutinized the solution. i.e., it's a wheel.&lt;/p&gt;
&lt;p&gt;The HTTP features are &lt;em&gt;ETags&lt;/em&gt; and &lt;em&gt;conditional requests&lt;/em&gt; and enable &lt;em&gt;optimistic concurrency&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id="etags"&gt;ETags&lt;/h2&gt;
&lt;p&gt;An &lt;a href="https://datatracker.ietf.org/doc/html/rfc7232#section-2.3"&gt;ETag&lt;/a&gt; (AKA entity-tag) addresses the &amp;quot;lost update&amp;quot; problem where there are two clients of an API that have received the representation of a version of an entity. Still, another client updates the entity before the other: the second update causes the first the be &amp;quot;lost.&amp;quot; See the following diagram for a visualization:&lt;/p&gt;
&lt;p&gt;&lt;img src="./assets/lost-update-sequence.png" class="img-fluid" alt="Lost-update" /&gt;&lt;/p&gt;
&lt;p&gt;An ETag addresses accidental overwrite by &lt;em&gt;versioning&lt;/em&gt; the resource with an entity-tag (a hash of the representation, a version, etc.). When a client requests a resource, the server may include an ETag validator header field with an entity-tag value in the response. The URI of the resource, along with that entity-tag, constitutes an identifier for a particular version of an entity.&lt;/p&gt;
&lt;p&gt;When a client requests a change to the entity, it includes the entity-tag as a basis version with a conditional header field (like &lt;code&gt;If-Match&lt;/code&gt;.)  The server responds with &lt;code&gt;412 (Precondition Failed)&lt;/code&gt;, and the client can retrieve the latest version, re-apply their change, and re-send. See the following diagram for a visualization:&lt;/p&gt;
&lt;p&gt;&lt;img src="./assets/lost-update-solution-sequence.png" class="img-fluid" alt="Lost-update" /&gt;&lt;/p&gt;
&lt;h2 id="falling-back-to-date-and-time"&gt;Falling back to date and time&lt;/h2&gt;
&lt;p&gt;Even if you use date and time, &lt;strong&gt;HTTP also covers you with other precondition header fields involving modification date&lt;/strong&gt;. The &lt;code&gt;If-Unmodified-Since&lt;/code&gt; and &lt;code&gt;If-Modified-Since&lt;/code&gt; precondition header fields allow you to pass modification date preconditions to make a request conditional. When the precondition isn't met, a &lt;code&gt;412 (Precondition Failed)&lt;/code&gt; status code will be in the response, or for &lt;code&gt;GET&lt;/code&gt; or &lt;code&gt;HEAD&lt;/code&gt;, a &lt;code&gt;304 (Not Modified)&lt;/code&gt; status code will be in the response.&lt;/p&gt;
&lt;p&gt;The initial GET of a resource that supports modification dates in conditional requests will include a &lt;code&gt;Last-Modified&lt;/code&gt; header field validator. The &lt;code&gt;Last-Modified&lt;/code&gt; validator is in the form of an &lt;a href="https://datatracker.ietf.org/doc/html/rfc7231#section-7.1.1.1"&gt;HTTP-date&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="being-successful"&gt;Being Successful&lt;/h2&gt;
&lt;p&gt;RFC 7232, the HTTP 1.1 specification, section 2.3 describes the &lt;em&gt;entity-tag&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;An entity-tag is an opaque validator for differentiating between multiple representations of the same resource, regardless of whether those multiple representations are due to resource state changes over time, content negotiation resulting in multiple representations being valid at the same time, or both.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This means that the ETag value depends on the content-type, so two &lt;strong&gt;different representations of the same resource should have different ETag values&lt;/strong&gt; (e.g., one gzip encoded, one not.)&lt;/p&gt;
&lt;p&gt;This also means that the ETag value is opaque to requestors but does point out that one of the intents of ETags to be &lt;strong&gt;an alternative to using a date-time stamp due to lack of accuracy&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="patch"&gt;PATCH&lt;/h3&gt;
&lt;p&gt;Using &lt;code&gt;PATCH&lt;/code&gt; with something like &lt;a href="https://jsonpatch.com/"&gt;JSONPatch&lt;/a&gt; may seem to help alleviate conflicts by providing more granularity in what is changing. Technically true, to implement this would be non-trivial. The ETag specifics a tag of that edition of the entire resource, not any one field. While comparing a change against a delta between two editions of a resource (keeping in mind those editions may not be adjacent) might be one technique for dealing with that, &lt;strong&gt;creating deltas between arbitrary versions of the same resource is non-trivial&lt;/strong&gt;. You could introduce that sort of thing. Something like event-sourcing might enable that. But remember that there may be interdependencies between properties of a resource, and just because the current request changes a property that hasn't changed since the resource was retrieved doesn't mean there isn't still a conflict.&lt;/p&gt;
&lt;h3 id="last-modified"&gt;Last-Modified&lt;/h3&gt;
&lt;p&gt;Remember that &lt;code&gt;Last-Modified&lt;/code&gt; uses &lt;a href="https://datatracker.ietf.org/doc/html/rfc7231#section-7.1.1.1"&gt;HTTP-date&lt;/a&gt; format, so &lt;strong&gt;&lt;code&gt;Last-Modified&lt;/code&gt; only supports second granularity&lt;/strong&gt;. With multiple origin servers, more than second granularity may be needed to be accurate 100% of the time.&lt;/p&gt;
&lt;h4 id="if-unmodified-since"&gt;If-Unmodified-Since&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;If-Unmodified-Since&lt;/code&gt; is used with state-changing methods like PUT, POST, DELETE, and PATCH to avoid accidental overrides (lost updates). &lt;code&gt;If-Unmodified-Since&lt;/code&gt; imposes the precondition &lt;em&gt;update this entity only if it hasn't changed since the provided date-time&lt;/em&gt;. &lt;strong&gt;Use &lt;code&gt;If-Unmodified-Since&lt;/code&gt; to avoid lost update problems when second granularity is not a problem&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id="if-modified-since"&gt;If-Modified-Since&lt;/h4&gt;
&lt;p&gt;When used with &lt;code&gt;GET&lt;/code&gt; or &lt;code&gt;HEAD&lt;/code&gt;, the &lt;code&gt;If-Modified-Since&lt;/code&gt; header field imposes the precondition &lt;em&gt;respond with &lt;code&gt;304 (Not Modified)&lt;/code&gt; and not with an entity representation if the modification date of the identified resource is not more recent than the date provided&lt;/em&gt;. &lt;strong&gt;Use &lt;code&gt;If-Modified-Since&lt;/code&gt; to avoid re-transferring the same data&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="conflict"&gt;&lt;code&gt;409 (Conflict)&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;409 (Conflict)&lt;/code&gt; may sound like an appropriate response to a conditional PUT/POST/PATCH request, except that &lt;code&gt;412 (Precondition Failed)&lt;/code&gt; is expected. &lt;strong&gt;Response status code &lt;a href="https://datatracker.ietf.org/doc/html/rfc7231#section-6.5.8"&gt;&lt;code&gt;409&lt;/code&gt;&lt;/a&gt; should be used when something about the current state of the resource means that the server cannot change it&lt;/strong&gt;. Also, if you have chosen not to use HTTP precondition features and have included something &lt;em&gt;in the representation of the entity&lt;/em&gt; for versioning (like last-modified-date, see above), then &lt;code&gt;409 (Conflict)&lt;/code&gt; is appropriate to signify a potential accidental overwrite or lost update.&lt;/p&gt;
&lt;h3 id="leveraging-existing-implementations"&gt;Leveraging Existing Implementations&lt;/h3&gt;
&lt;p&gt;Azure Cosmos DB implements ETags and &lt;code&gt;Last-Modified&lt;/code&gt; to be leveraged to support the versioning of resources in your Web API. Technically the ETag is a version of the representation that Cosmos DB provides, so consider generating a new ETag based on what Cosmos DB provides, especially if you support more than one content-type (like XML). Suppose you have the concept of a database DTO or database models different from your MVC models. In that case, you should consider custom entity-tag generation based on the Cosmos-supplied entity-tag.&lt;/p&gt;
&lt;p&gt;To leverage the Cosmos-supplied entity-tag, retain it and re-send it in any state-changing requests to Cosmos in the &lt;code&gt;If-Match&lt;/code&gt; header field. If the entity-tags do not match, Cosmos DB will respond with &lt;code&gt;412&lt;/code&gt;, and the Cosmos DB library will throw a &lt;code&gt;CosmosException&lt;/code&gt; with &lt;code&gt;StatusCode&lt;/code&gt; == &lt;code&gt;HttpStatusCode.PreconditionFailed&lt;/code&gt;.&lt;/p&gt;
&lt;!--
title Lost Update Problem

participant "Client 1" as Client1
participant "Client 2" as Client2
participant API

Client1-&gt;API:""GET /resource/123""
activate Client1
Client1&lt;--API:""200 OK""\n//resource v1 representation//

create Client2
Client2-&gt;API:""GET /resource/123""
activate Client2
Client2&lt;--API:""200 OK""\n//resource v1 representation//
Client1-&gt;API:""PUT /resource/123""
Client1&lt;--API:""200 OK""\n//resource v2 representation//
deactivateafter Client1
destroyafter Client1

Client2-#red&gt;API:""PUT /resource/123""
note over Client1,API#pink:Client 2 is updating the resource based from **v1**, not **v2**:\n&lt;align:center&gt;the v2 update is "lost" to //Client 2//&lt;/align&gt;
Client2&lt;--API:""200 OK""\n//resource v3 representation//

--&gt;
&lt;!--
title Lost Update Solution

participant "Client 1" as Client1
participant "Client 2" as Client2
participant API

Client1-&gt;API:""GET /resource/123""
activate Client1
Client1&lt;--API:""200 OK""\n//resource v1 representation//

create Client2
Client2-&gt;API:""GET /resource/123""
activate Client2
Client2&lt;--API:""200 OK""\n//resource v1 representation//
Client1-&gt;API:""PUT /resource/123\nIf-Match: v1""
Client1&lt;--API:""200 OK""\n//resource v2 representation//
deactivateafter Client1
destroyafter Client1

Client2-&gt;API:""PUT /resource/123\nIf-Match: v1""

Client2&lt;--API:&lt;color:#red&gt;""412 Precondition Failed\nBasis version of resource is out of date""&lt;/color&gt;
--&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="../assets/accidental-overwrite.jpg" class="img-fluid" alt="A stuffed tiger corrupted appearance due to accidental overwrite"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Being-Successful-With-Domain-Driven-Design--Minimal-Complexity-Part-3</id>
		<title>Being Successful with Domain-Driven Design: Minimal Complexity, Part 3</title>
		<link href="http://blog.peterritchie.com/posts/Being-Successful-With-Domain-Driven-Design--Minimal-Complexity-Part-3" />
		<updated>2023-06-12T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/complex-relationships.jpg" class="img-fluid" alt="complex-relationships" /&gt;&lt;/p&gt;
&lt;p&gt;With a name like &amp;quot;Domain-Driven Design,&amp;quot; it should be no surprise there is a major focus on the domain and has a huge influence on implementation. We've focused mostly on strategic design patterns and practices like Ubiquitous Language, Bounded Context, etc. But I've also covered a bit of tactical design and implementation. I've transitioned from strategical patterns--that deal with being explicit with domain concepts (Ubiquitous Language, Bounded Contexts)--to tactical patterns that have focused on directly translating domain concepts into code structure or coding patterns (like Services and Aggregates.)&lt;/p&gt;
&lt;p&gt;The concepts and their consistency boundaries are only a couple of things that contribute to the complexity of non-trivial domains. For example, the work required to implement a domain is independent of its concepts and consistency boundaries. Additionally, the system's quality attributes and technical constraints are major influencers on the internal structure of that system. The next set of Domain-Driven Design patterns I'll get into (&lt;em&gt;tactical&lt;/em&gt; patterns) aid in this respect. As we get closer to implementation, the focus turns more towards isolating domain complexity from implementation complexities.&lt;/p&gt;
&lt;p&gt;As with many things in Domain-Driven Design, &lt;em&gt;x&lt;/em&gt; for the sake of &lt;em&gt;x&lt;/em&gt; is not the intention. Many things in most methodologies can be regurgitated and used by rote, providing little to no value. The principles and practices in Domain-Driven Design are best utilized with purpose and intent. Architectural layering is a good example. Each layer needs a reason for being (a purpose) with unidirectional  independence of its concepts from another layer's concepts. Just any two groupings won't do; without the purposeful intent of having two layers with a unidirectional dependency, you'll never gain the benefits of layering. You end up with the added burden of managing a structure that does not give you any layered benefits.&lt;/p&gt;
&lt;p&gt;The minimum complexity for layers is that two groups of concepts (contexts) are uni-directionally interdependent. In Domain-Driven Design, those layers focus on isolating the concerns of a User Interface, Application, Domain, and Infrastructure.&lt;/p&gt;
&lt;p&gt;The Application layer may seem unique to Domain-Driven Design. There are few patterns/methodologies that isolates the concern that the application layer deals with. Ports and Adapters (Hexagonal) and, by extension, Clean Architecture recognize and isolate high-level &lt;em&gt;use cases&lt;/em&gt; from both the domain and the implementation details of a UI. This is the role of the Application layer in Domain-Driven Design to further isolate the domain from how any use case uses the domain (a use case &lt;em&gt;applies&lt;/em&gt; or &lt;em&gt;realizes&lt;/em&gt; the domain). In Ports and Adapters, uses-cases (or, as Cockburn describes, uses-cases) are sequences of interactions between the system and users/actors. With the recognition of these interactions, they can now be isolated as collaborations within the Application layer.&lt;/p&gt;
&lt;p&gt;There are other patterns that isolate interaction behavior structurally within collaborations like the Adapter pattern, but I'll save that for another day.&lt;/p&gt;
&lt;p&gt;A UI may have to deal with different form factors, communication protocols, execution contexts, etc. A loosely coupled UI involves designing an interface that takes all of those things into consideration to be successful. A web-based UI requires a backend that supports open protocols and standards. Protocols and standards relating to implementation or delivery are merely constraints on how a system is implemented. At some level, the domain needs to operate correctly regardless of those constraints.&lt;/p&gt;
&lt;p&gt;Layers are like different team roles, all working together simultaneously to accomplish specific types of goals. Bounded contexts are also like multiple teams, sometimes like a night shift and a day shift or an on-shore and an off-shore team. These types of teams work with some level of independence: shifts may never work together simultaneously, and on- and off-shore teams only work together for a brief time with much more structured communication.&lt;/p&gt;
&lt;p&gt;Recognizing and planning for how teams contribute to the same goals is key for these teams to be effective. It's the recognition that different parts of a larger system need different levels of independence. With teams, this is to utilize resources effectively: like how shifts can use limited resources (human skills) across more of the day (e.g., 24 hours instead of 8.)  Conway's law is just an observation (i.e., a reality). A team (or teams) structure imposes a means and cadence to communication. How often and the way inter-team communications occurs has implicit limits on that communication.&lt;/p&gt;
&lt;p&gt;Recognizing and working with that communications structure can make teams much more successful. Domain-Driven Design makes domains and sub-domains first-class citizens within the practices. Many aspects of architectural and social boundaries can affect the release of a product. A Bounded Context is more than a consistency boundary or scope of a domain model. A Bounded Context also involves work products (deployments, deliverables) and team organization.&lt;/p&gt;
&lt;p&gt;For example, the consistency boundary of a mortgage loan application becoming complete and submitted is a fairly obvious boundary and context. Still, the amount of work involved to support that might be fairly large. The number of people implementing and supporting that context might amount to several teams. The complexity of dealing with several teams of people to deliver parts of the same system can be enormous. Domain-Driven Design also gives us some patterns and practices to address those complexities. You may need to split a domain into more bounded contexts because one context is too complex for a single team to manage. When we start to talk about separating work across teams, we're still talking about bounded contexts. For similar reasons, you may need to split a domain into more bounded contexts (and thus &amp;quot;sub-domains&amp;quot;) simply because of an existing team or reporting structure.&lt;/p&gt;
&lt;p&gt;For delivery to be more successful, it's important to recognize the different teams, reporting structures, team motivations, and missions within the strategic design of the Bounded Contexts. How two teams and how the work product of those two teams interact is unique. Fortunately, there are some patterns to address the dependencies between two teams and their work products that help us address their inherent complexities. I'm assuming there's always some degree of interdependency and independence, and I'm ignoring mutually independent (Separate Ways) and Big Ball of Mud relationships/structures.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;It's worth noting that as soon as two contexts are recognized the need to translate between the two becomes a reality. As context become complex to the point of being bounded context so too does the need to recognize and isolate translation. Much of what we do in Domain-Driven Design is the isolation of concepts, concerns, responsibilities, etc. The need for a translation layer is no different.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There is a spectrum to the degree of independence of two teams and or the independence of their work products. The teams are very dependent on one end, while the other is extremely independent. With Domain-Driven Design, very dependent teams exhibit a lot of domain overlap. With a lot of domain overlap, you can have an interdependence where teams work as equals or partners. This partnership can manifest in an early re-org of people working on existing or legacy systems. That partnership may start with different teams working on separate parts of the codebase. This partnership may only be one step in the evolution of the teams; the next step is often to organize teams toward the Shared Kernel model.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;A spectrum of options is a synonym for &lt;em&gt;infinite combinations&lt;/em&gt;. It's nice to have flexibility, but an endless set of possibilities is hard to map to a finite set of patterns, and it's hard to use established practices if every situation is novel. There are some ideas and structures that Domain-Driven Design details to add some granularity to the domain we're modeling so that we can more easily map complexity to the patterns and practices that address them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the Shared Kernel model, the team carves off a separate shared codebase or a shared component to contain all the things that two or more teams will always or almost always mutually require. A Shared Kernel model involves organizational behavior, like specific responsibilities, code areas, accountability, etc. But Shared Kernel is a fairly casual relationship. With more formality between two teams or components, you usually see an Upstream/Downstream relationship form. It is easy to view the users of the Shared Kernel downstream dependents and evolve to a more formal Upstream/Downstream relationship. A Customer/Supplier model may emerge in cases like this.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;A shared codebase is more casual than a shared component, but a shared component promotes more independence. At the component level, it's important to ensure that autonomy hasn't allowed the teams to deviate from a shared plot, which Continuous Integration is intended to address. The component should be integrated with client code at every opportunity. The intent of a Published Language is for all contexts to be on the same page in understanding that domain. It's not that all contexts will adopt the published language as their domain, but they know how to translate in and out of their domain.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the Customer/Supplier model, one team owns a component the other uses as the consumer of the component's capabilities. The team that owns the component is the Supplier, and the team that uses it is the Customer. With this model comes organizational behavior with more specific responsibilities, more planning, and scheduling. With this increased independence, the supplier team has very specific goals in which the customer team has a stake and influence, represented in a release cadence and a roadmap. The Customer is usually the driver of what capabilities the component provides next. The integration model of Customer/Supplier is usually a web service.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;In a Upstream/Downstream model, there will almost always be some form of Published Language--usually more formal than just a description, often a specification. Translation becomes more formal in a Upstream/Downstream model, often resulting in a translation layer. If the Upstream/Downstream relationship is between two Bounded Contexts with a high degree of independence an Anticorruption Layer is used on one side to manage the differences communicating between the two domains.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Shared kernel and two-team customer/supplier relationships often exist due to the reporting structure or that reporting structure was created to split work across two teams. In a more product-focused organization, you may have a Customer/Supplier model with more than one customer. Multi-customer relationships can be witnessed in larger organizations with things like shared libraries. The customers are still driving the capabilities that the component and team provide them, but it can become more formal to manage the unique requirements of different customers. The supplier team is often more organized or formal and may have more of a product strategy with a product vision and mission that helps guide their work.&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;With more formal relationships come more formal expectations. Those expectations may come in the form of specifications and processes. Continuous Integration is an example of a process that continuously validates integrability. Potentially less formal than a specification may be a Published Language--which in its simplest form is a description of the concepts of a domain. (more complex forms would be varying degrees of specifications.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Communications with a customer/supplier model within the same organization can be informal. What the team is working on and how they interact with customers might be more like partnerships; teams may work closely together to implement and integrate components. The number of customers or distance from customers can impact this informalness. The further away a customer is (different division, different organization, different company) may impose more formality to the relationship. The work product of the supplier team may be viewed more like a product. And while customers may drive that product, it may be much more formal to the point where the component is independent of any single customer. This type of relationship may be structured more like a service with a very specific or well-specified interface. Moving towards a well-specified interface is the intent of an Open Host Service where the component is remotely accessed (a service) with a specified protocol and interface.&lt;/p&gt;
&lt;p&gt;As a customer has less influence on a service, they may become completely dependent on the supplier team to provide the capabilities they require. They accept the risk that the supplier team may not provide the necessary capabilities in the future. This is extreme, and either no organization would accept this risk, or it is a temporary relationship. In reality, the different models aren't mutually exclusive, but there is a tendency towards one of them. e.g., a relationship tends to be less like a customer/supplier relationship and more like one completely conforming to another. The recognition of this relationship is called the Conformist model.&lt;/p&gt;
&lt;p&gt;highlight: Recognize change will happen but don't try to create a design that accommodates all change.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/complex-relationships.jpg" class="img-fluid" alt="complex-relationships"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Being-Successful-With-Domain-Driven-Design--Minimal-Complexity-Part-2</id>
		<title>Being Successful with Domain-Driven Design: Minimal Complexity, Part 2</title>
		<link href="http://blog.peterritchie.com/posts/Being-Successful-With-Domain-Driven-Design--Minimal-Complexity-Part-2" />
		<updated>2023-05-29T00:00:00Z</updated>
		<content>&lt;p&gt;In part one, I talked about the complexity in the language used to communicate the domain. Domain-Driven Design (DDD) deals with that complexity by isolating the concepts in a clear language that domain experts understand. Ubiquitous Language helps form the basis of all the other patterns and practices in Domain-Driven Design through the clear isolation of domain &lt;em&gt;concepts&lt;/em&gt;. The DDD pattern language context map provides a good example of isolating concepts (in this case, Domain-Driven Design concepts):&lt;/p&gt;
&lt;p&gt;&lt;img src="/assets/ddd-pattern-language.png" class="img-fluid" alt="ddd-pattern-language" /&gt;&lt;/p&gt;
&lt;p&gt;Isolating individual concepts, naming them, and detailing how they relate allows each to be thought about independently.  We can focus on parts of &amp;quot;Domain-Driven Design&amp;quot; because a Context Map details that isolation.&lt;/p&gt;
&lt;p&gt;I'll dig deeper into the Aggregate and Service patterns in this part two. Aggregate and Service enable and embody major domain concepts.&lt;/p&gt;
&lt;p&gt;An aggregate is the realization of a logical consistency boundary and the operations contributing to that consistency. An aggregate is a composition of several domain objects: At least one entity object and usually several value objects. Each domain object maintains its own consistency (it has invariants.) A date is a composition of a day, month, and year, but February 31, 1981 is not a valid date.  We differentiate an aggregate from any grouping of domain objects because of the invariants and rules beyond that of simply a collection of consistent domain objects. An aggregate models that cross-object consistency requirement.&lt;/p&gt;
&lt;p&gt;Aggregates map to major domain concepts and significant domain behavior associated with a particular domain object (the root). The root is the object of behavior and acts as a gateway to the other objects the aggregate comprises. The root takes on the responsibility of maintaining the consistency of the entire aggregate. The complexity of that composition and the consistency are separated from complexities outside the natural boundary of the aggregate.&lt;/p&gt;
&lt;p&gt;An aggregate is not a design choice; it is a natural role that a major domain entity plays in the domain that requires recognition in a domain model. Some domain entities naturally take on certain behavior that affects other domain objects. All the behavior must happen in certain ways and have expectedly consistent results. Those consistent results (or state) abide by rules and invariants--it's consistent &lt;em&gt;because&lt;/em&gt;... With a loan application, for example, there's no such thing as having negative assets (particularly: it's not a consistent loan application when it contains assets with negative value.) If you &lt;em&gt;owe&lt;/em&gt; money, that's a liability.&lt;/p&gt;
&lt;p&gt;When understanding and modeling a domain, I like to accurately map behavior to domain concepts that logically have that (or any) behavior. Sometimes it's easy to mis-associate behavior with static concepts when those are the major concepts in the domain. A loan, for example, is a major concept in many financial domains, but it does not exhibit behavior; it's static. A loan is the subject of many behaviors in a financial domain but is just a contract (or a specification.) We know we have complexity to deal with. Mis-associating behavior reduces clarity, making things needlessly more complex.&lt;/p&gt;
&lt;p&gt;Starting out understanding a domain, I find focusing primarily on behavior and activities useful. Everything else in a domain is ultimately the subject of a behavior or activity, so I don't model them explicitly. For example, the role of underwriter &lt;em&gt;approves&lt;/em&gt; a loan application. A loan application can be approved when the following rules are satisfied: a) the Debt-To-Income Ratio is below 43%, and b) etc... Debt-To-Income Ratio is modeled as an attribute of a loan application and covered in the activity of Approving a Loan. Information that isn't the object of a behavior also adds needless complexity.&lt;/p&gt;
&lt;p&gt;When certain logic doesn't require a single object or doesn't require a &lt;em&gt;particular state&lt;/em&gt; and requires &lt;em&gt;particular objects&lt;/em&gt;, it might not be accurate to model the logic as part of an &lt;em&gt;aggregate&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A Service is the realization of a collaboration between several objects. The concept of that service exists because it is not the natural behavior of a domain &lt;em&gt;entity&lt;/em&gt;. A Domain Service is the realization of a collaboration between one or more domain entities. It involves business logic and or business rules that may affect the state of those domain entities. An application service is the realization of a collaboration between one or more domain services, domain objects, and an infrastructure service. And an infrastructure service is a collaboration with a framework or the &amp;quot;outside.&amp;quot;  The Service pattern recognizes complexity by isolating logic that is otherwise unrelated.&lt;/p&gt;
&lt;p&gt;Look again at the Domain-Driven Design pattern language. If we always had to deal with all the complexities detailed in that diagram, it would be much harder to get things done promptly. The fact that the concepts are delineated and we can deal with them in isolation simplifies working with them. Separating interaction-only logic into a separate service from the object behavior affecting their state means we can think about and work with those concepts in isolation. Those concepts are now more loosely-coupled, and we obtain the benefits of loose coupling.&lt;/p&gt;
&lt;p&gt;These definitions are easy enough to understand but can be confusing when it comes time to put them into practice. Sometimes the confusion stems from a backward approach to implementing software systems. Teams work backward from patterns when looking for the opportunity to use patterns. It's more successful in understanding the domain and then matching domain concepts to patterns and practices. For example, I've seen people approach a domain with questions like &amp;quot;What are all the entities?&amp;quot; or &amp;quot;What are all the services?&amp;quot;  While we might be able to answer those questions after we've understood the domain and started to design solutions, approaching it from that perspective at that stage of understanding can pervert the interpretation of the domain. Services can be hard to recognize and implement when the domain concepts are not yet clearly isolated.&lt;/p&gt;
&lt;p&gt;Sometimes it can be easy to delineate interaction logic in a collaboration from the business logic; often, it is not. In a financial domain, &lt;em&gt;transferring funds&lt;/em&gt; as a capability can be easily viewed as the behavior of an account, for example. It involves accounts, obviously, so why would it not be an &lt;em&gt;account behavior&lt;/em&gt;? But what happens when transferring funds? The situation's complexity comes from the fact that more than one account is involved, and the consistency of each account needs to be managed independently of the other(s).  A funds transfer succeeds or fails, but has no state of its own--any change in state is encapsulated in the objects participating in the collaboration.&lt;/p&gt;
&lt;p&gt;A clear understanding of the domain concepts is vital to project the isolation of those concepts into design elements more accurately. Modeling domain knowledge requires the delineation and understanding of the concepts as well as correctly associating all the behavior and attributes of those concepts. Maintaining this model is a process of managing complexity, but it only happens in stages. Managing these complexities is an ongoing and iterative process. The more complex a domain is, knowledge fragmentation amongst domain experts is more likely. It's highly unlikely that a single person completely understands the domain. This knowledge fragmentation is one reason we model the domain iteratively, recognizing that understanding evolves over time.&lt;/p&gt;
&lt;p&gt;The Aggregate and Service patterns model parts of the domain similarly but provide a means to recognize separate parts of the domain: independent of the level at which they apply as well as how they affect state.  Service operates at a higher level to model an activity, a collaboration of objects.  An aggregate is the composition of several domain objects that must abide by the same invariants and be consistent in the presence of each other.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;In part one, I talked about the complexity in the language used to communicate the domain. Domain-Driven Design (DDD) deals with that complexity by isolating the concepts in a clear language that domain experts understand. Ubiquitous Language helps form the basis of all the other patterns and practices in Domain-Driven Design through the clear isolation of domain &lt;em&gt;concepts&lt;/em&gt;. The DDD pattern language context map provides a good example of isolating concepts (in this case, Domain-Driven Design concepts):&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Being-Successful-With-Domain-Driven-Design--Minimal-Complexity-Part-1</id>
		<title>Being Successful With Domain-Driven Design: Minimal Complexity, Part 1</title>
		<link href="http://blog.peterritchie.com/posts/Being-Successful-With-Domain-Driven-Design--Minimal-Complexity-Part-1" />
		<updated>2023-05-19T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/concepts-contexts-and-boundaries.jpg" class="img-fluid" alt="Concepts, Context, and Boundaries. Abstract Thought" /&gt;
The Domain-Driven Design book (the &amp;quot;Blue Book&amp;quot;) includes &amp;quot;Tackling complexity at the heart of software&amp;quot; in the title. While &amp;quot;complexity&amp;quot; can be subjective, the takeaway is that Domain-Driven Design intends to address complex software systems. The principles and practices in Domain-Driven Design have their complexities, so for Domain-Driven Design to add value, it needs to address existing/expected complexity and attempt to be net-positive for simplicity.&lt;/p&gt;
&lt;p&gt;Interestingly, the title of the Blue Book alludes to questions about &lt;em&gt;what&lt;/em&gt; complexity is at the heart of software. Subjectively subjective, but we can look to the intent of some of the patterns and practices to deduce some types of complexity that Domain-Driven Design adequately addresses in the design of software systems.&lt;/p&gt;
&lt;p&gt;For this series, I'll tranche away some of the patterns as essential complexity (essential complexity of &lt;em&gt;both&lt;/em&gt; Domain-Driven design and the design of almost all software design):  Entities, Value Objects, Modules, Layered Architecture, Factories, and Repositories. Any modular software system must deal with identity, value, creation, and storage. There's nothing new about layered architecture, but Domain-Driven Design does detail the isolation of specific responsibilities (like Domain and Infrastructure) that I'll cover. Practices like Side-Effect Free Functions, Standalone Classes, Intention-Revealing Interfaces, Continuous Integration, Assertions, and Declarative Style are aspects of long-championed techniques like cohesion, loose-coupling, naming standards, or functional programming (in my opinion).&lt;/p&gt;
&lt;p&gt;None of what I've tranched off are unimportant, but they have been tried and true before Domain-Driven Design, and I want to focus on added value in Domain-Driven Design. To that end, I'll focus on Ubiquitous Language, Bounded Context, Context Map, Aggregates, Services, Domain Layer, Generic Subdomains, Segregated Core, Anti-Corruption Layer, and Core Domain; and touch on Evolving Order.&lt;/p&gt;
&lt;h3 id="clean-concepts-contexts-and-boundaries"&gt;Clean Concepts, Contexts, and Boundaries&lt;/h3&gt;
&lt;p&gt;If I had to distill the intent of Domain-Driven Design to a single statement, it might be &amp;quot;be explicit.&amp;quot;  Or, more explicitly: &amp;quot;Be explicit with boundaries.&amp;quot;  Software systems are not the only source (or victim) of complexity. There's a whole science devoted to it: Complex Adaptive Systems. Not to oversimplify Complex Adaptive Systems, but systems with sufficient complexity are inherently unpredictable and exhibit &lt;em&gt;emergent behavior&lt;/em&gt;, among other things. Meaning that complex systems will do what they're going to do, and we can only sometimes predict what they will do. Sometimes that emergent behavior is beneficial; sometimes, it isn't. To make systems more predictable (and get the benefits that provides), we have to reduce complexity. The complexity of complex systems arises from the number of dependencies, relationships, and interactions. Each unbounded interconnection increases complexity exponentially.&lt;/p&gt;
&lt;p&gt;Complex adaptive systems theory is why explicit boundaries are a major aspect of how Domain-Driven Design combats complexity in software to produce more reliable and robust systems. Explicitness is important here; we're not looking for any-old boundaries. We're looking to constrain and isolate areas of the system based on purpose, meaning, and intent. We could chalk this up as simply an exercise in cohesion, but Domain-Driven Design focuses on getting to and clarifying that purpose, meaning, and intent.&lt;/p&gt;
&lt;p&gt;Explicitness starts with unambiguous concepts, descriptions, and terms. If people aren't communicating the same concept things aren't going to get simpler. I speak about &lt;em&gt;Naming Things&lt;/em&gt;, and part of what makes that difficult, I've decided, is language (or English). Stemming from human nature, we try to classify an ever-increasing set of concepts with a finite set of words, syntax, and semantics. The first step to explicit boundaries is the agreement on what they are: agreement on the concepts and to which explicit context they apply—the Ubiquitous Language.&lt;/p&gt;
&lt;p&gt;The value of Ubiquitous Language isn't just that there is an agreed-upon vocabulary. The added value to a Ubiquitous Language is what it accounts for. The Ubiquitous Language recognizes classifications of concepts, classifications common to most software systems. Classifications that the Ubiquitous Language fosters and isolates: individuals, invariants and consistency rules, operations, processes, collaborations, commands, events, views, and values/properties. By &amp;quot;individuals,&amp;quot; I don't just mean people, but anything that exhibits individuality (aka &amp;quot;entity.&amp;quot;)&lt;/p&gt;
&lt;p&gt;Imagine an amorphous &amp;quot;loan&amp;quot; concept in the financial industry. People apply for loans, obtain loans, and pay back loans. Getting a loan involves evaluating personal information (credit rating, assets, liabilities, etc.). Paying back a loan consists of a term, an interest rate, a payment schedule, etc. Credit rating, assets, liabilities, term, interest rate, and payment schedule are six interconnected concepts. With six concepts (with each having five interconnections to the others), there are 30 interconnections. Or 30 complexity points. But, if we think of these six concepts as two different semi-independent contexts: &amp;quot;loan application&amp;quot; and &amp;quot;loan servicing,&amp;quot; we end up with two contexts (and one interconnection) with three concepts (or three interconnections) totaling six interconnections. We've gone from 30 complexity points to 6 simply by defining the actual contexts better. In other words, we're being more explicit.&lt;/p&gt;
&lt;p&gt;Explicitness like this--delineating elements of a set into two groups connected by a specific relationship--is creating a boundary between two contexts. This is a very simple example of Bounded Context. As the name implies, Bounded Context is an explicit contextual boundary: where one context ends and another begins. This is a domain's macro level, recognizing that Loan Servicing can only happen after Loan Application is successful. This particular boundary is based on a temporal or procedural boundary. Phases or steps are a good way of organizing domains into bounded contexts.&lt;/p&gt;
&lt;p&gt;In these two contexts, the word &amp;quot;loan&amp;quot; exists in both. The word &amp;quot;loan&amp;quot; is used in the application context as well as in the servicing context. But, in the application context, the meaning is really &amp;quot;loan application,&amp;quot; and in the servicing context, it really means &amp;quot;serviced loan&amp;quot;. Understanding that servicing depends on an approval event in a loan application phase (or activity) allows us to realize an explicit boundary. Sometimes it's as easy as this, but often it's not. There are other ways of teasing out boundaries (or contexts), almost always involving vocabulary elements.&lt;/p&gt;
&lt;p&gt;Sometimes you've got overloaded terms like &amp;quot;loan&amp;quot;; sometimes, you have different terms like different &lt;em&gt;rules&lt;/em&gt;. Different rules are typically applied in different scenarios or involve different parameters. Different rules offer a window into recognizing different contexts with a boundary in-between. You may recognize concepts like this (events, operations, rules/invariants) from the larger list I mentioned above. A Ubiquitous Language can also account for individuals and entities, commands (often related to an activity), views (reports, screens, results), collaborations, and attributes or properties attributed to individuals and entities. Additionally, attributes or properties can be involved in criteria, and categories or subtypes may group individuals and entities.&lt;/p&gt;
&lt;p&gt;Working towards a Ubiquitous Language is working towards concepts more independent from each other. Independent concepts are themselves individual contexts. Any defined concept has a defined context with understandable boundaries. Keeping the complexity of one context bound from others keeps the essential complexity within that context and reduces the accidental complexity that arises from blended contexts.&lt;/p&gt;
&lt;p&gt;Domain-Driven Design adds value when you have a minimal complexity, when a subject matter has multiple terms per classification. Terms can be classified as entities, processes, phases, events, rules, views, etc. The focus of this post was a level of complexity where boundaries are recognizable in the nuances of the vocabulary. In future posts, I'll dig deeper into different the subject matter (or domain) classifications, how you can isolate the complexities of each, and the parts of Domain-Driven Design that apply.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/concepts-contexts-and-boundaries.jpg" class="img-fluid" alt="Concepts, Context, and Boundaries. Abstract Thought"&gt;
The Domain-Driven Design book (the "Blue Book") includes "Tackling complexity at the heart of software" in the title. While "complexity" can be subjective, the takeaway is that Domain-Driven Design intends to address complex software systems. The principles and practices in Domain-Driven Design have their complexities, so for Domain-Driven Design to add value, it needs to address existing/expected complexity and attempt to be net-positive for simplicity.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/installing-dotnet-framework-4-5-targeting-pack</id>
		<title>Installing .NET Framework 4.5 Targeting Pack</title>
		<link href="http://blog.peterritchie.com/posts/installing-dotnet-framework-4-5-targeting-pack" />
		<updated>2023-02-05T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/DALL%C2%B7E-2023-02-05-13.14.52--ludites-frustration-with-errors-in-integrated-development-environments-(IDE)-pencil-and-watercolor.png" class="img-fluid" alt="When working in an IDE seems like working with crayons" /&gt;&lt;/p&gt;
&lt;p&gt;Something came up with a client around Live Dependency Validation in Visual Studio recently.  Digging into it I ran into several issues, one of which was the error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Severity	Code	Description	Project	File	Line	Suppression State
Error		The reference assemblies for .NETFramework,Version=v4.5 were not found. To resolve this, install the Developer Pack (SDK/Targeting Pack) for this framework version or retarget your application. You can download .NET Framework Developer Packs at https://aka.ms/msbuild/developerpacks	DependencyValidation	C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Current\Bin\amd64\Microsoft.Common.CurrentVersion.targets	1229	
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;.NET Framework 4.5 has been out of support since 2016, so its targetting pack isn't available for download.  I found a couple blogs posts about editing the modelproj file to add things like &lt;code&gt;ResolveAssemblyReferenceIgnoreTargetFrameworkAttributeVersionMismatch&lt;/code&gt; or a &lt;code&gt;PackageReference&lt;/code&gt; to &lt;code&gt;microsoft.netframework.referenceassemblies.net45&lt;/code&gt; but neither worked.&lt;/p&gt;
&lt;p&gt;One of the features of Visual Studio Installers is that they can be a one-stop-shop for all the things you're going to need to develop software (with or without Visual Studio).  One of these features is to install .NET targeting packs!  Although the latest version of Visual Studio doesn't include out-of-support components, prior versions of Visual Studio are available.  Visual Studio 2019 came out before .NET Framework 4.5 was completely unsupported (i.e. still had the option of paid support) so it offers the ability to install some targetting packs that are currently out of support.&lt;/p&gt;
&lt;p&gt;You can download older versions of Visual Studio via &lt;a href="https://bit.ly/vs-old"&gt;https://visualstudio.microsoft.com/vs/older-downloads/&lt;/a&gt;, which seems to redirect you eventually to Visual Studio Subscriptions downloads.  For our purposes, Visual Studio Community Editions works fine.&lt;/p&gt;
&lt;p&gt;To install, run the Visual Studio installer that you've downloaded (if you already have 2019 installed, run the already installed Visual Studio Installer and click &lt;strong&gt;Modify&lt;/strong&gt;) then click &lt;strong&gt;Continue&lt;/strong&gt; to go past the &lt;em&gt;set up a view things&lt;/em&gt; dialog. (if you have VS 2022 installed, this seems to do nothing.)&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Make sure you don't change any of the &lt;em&gt;workloads&lt;/em&gt; (if you have Visual Studio 2019 install already, some may be checked--don't uncheck them, that will uninstall them).&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src="/assets/vs2019-installer-45-targetting-pack.png" class="img-fluid" alt="Visual Studio Installer" /&gt;&lt;/p&gt;
&lt;p&gt;Click on the &lt;strong&gt;Individual Components&lt;/strong&gt; tab at the top (to the right of &lt;em&gt;Workloads&lt;/em&gt; and to the left of &lt;em&gt;Language packs&lt;/em&gt;.)  In the .NET section, find an check &lt;strong&gt;.NET Framework 4.5 targetting pack&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Click &lt;strong&gt;Install&lt;/strong&gt; or &lt;strong&gt;Install while downloading&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Once completed, you now have the .NET Framework 4.5 targetting pack.  If you're doing this in response to a .NET Framework 4.5 targetting pack error message in Visual Studio, exit and re-start Visual Studio--the error should go away (it does with the modelproj error.)&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Incidentally, the other issues I encountered are:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Full solution analysis for C# is currently disabled. You may not be seeing all possible dependency validation issues in C# projects. Options... Don't show again 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;... with no way to enable full solution analysis in a way that this notice recognizes and goes away.&lt;/p&gt;
&lt;p&gt;I'd appreciate any advice to resolve that that doesn't involve clicking &lt;strong&gt;Don't show again&lt;/strong&gt;.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/DALL%C2%B7E-2023-02-05-13.14.52--ludites-frustration-with-errors-in-integrated-development-environments-(IDE)-pencil-and-watercolor.png" class="img-fluid" alt="When working in an IDE seems like working with crayons"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/things-i-learned-attempting-azure-administrator-associate-part-2</id>
		<title>Things I Learned Attempting Azure Administrator Associate - Part 2 - Storage</title>
		<link href="http://blog.peterritchie.com/posts/things-i-learned-attempting-azure-administrator-associate-part-2" />
		<updated>2022-12-22T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/DALL%C2%B7E-2022-12-22-17.03.40--distributed-cloud-data-storage-in-the-style-of-salvator-dali.png" class="img-fluid" alt="distributed cloud data storage" /&gt;&lt;/p&gt;
&lt;p&gt;Azure Administrator Associate certification is about the skills required to be an Azure account, subscription, tenant, etc., administrator. If your end goal is to develop applications on Azure, that involves a lot of &lt;em&gt;administration&lt;/em&gt; of Azure resources. Regardless of your plan, storage administration is nuanced. This post focuses on some of those nuances, nuances that may not be apparent in the documentation.&lt;/p&gt;
&lt;h3 id="overview"&gt;Overview&lt;/h3&gt;
&lt;!--capabilities--&gt;
&lt;p&gt;Azure provides storage services for Files, Blobs, Queues, and Tables. Files are blobs that support access via SMB protocol, AKA File Shares. Blobs are web resources that support access via a URI (HTTP). Blob Storage supports two types of blobs: block blobs and page blobs. Table Storage supports key-based relational and document access. Queues support access to ephemeral messages.&lt;/p&gt;
&lt;p&gt;Azure Files has a File Sync feature that supports file-level replication across Windows Servers. The Azure File endpoint is also called the Cloud Endpoint and is part of a Sync Group that includes one or more Windows Server file shares.&lt;/p&gt;
&lt;p&gt;There are two performance options for Storage Accounts: Standard (general purpose v2) and Premium (for low latency.)&lt;/p&gt;
&lt;!--tiers/skus--&gt;
&lt;p&gt;Storage has a couple of storage tiers: Standard and Premium. Storage tiers provide different functionality at different costs. Blob Storage has several access tiers: Hot, Cool, and Archive. Access tiers offer a way to communicate the frequency and type of data access to reduce storage costs. Access tiers can be used to implement a lifecycle for data, moving to lower-cost tiers over time to reduce cost.&lt;/p&gt;
&lt;!--durability/high-availability--&gt;
&lt;p&gt;Storage supports data redundancy that makes copies of data to avoid loss due to infrastructure failure. There are several options: Locally-Redundant Storage (LRS), Zone-Redundant storage (ZRS), Geo-Redundant Storage (GRS), and Geo-Zone-Redundant Storage (GZRS). LRS stores three copies of the data asynchronously within a single data center. ZRS duplicates those 3 LRS copies across three availability zones (clusters) in a region. GRS duplicates those 3 LRS asynchronously to a single zone in a secondary region. GZRS duplicates the ZRS data across zones within the secondary region.&lt;/p&gt;
&lt;!--data protection--&gt;
&lt;p&gt;Recovery Services is the service responsible for storing backups and recovery points. Recovery Services stores data within Recovery Services Vaults.&lt;/p&gt;
&lt;p&gt;Encryption scopes logically group blobs or containers and assign an encryption key specific to that scope.&lt;/p&gt;
&lt;!--access control--&gt;
&lt;p&gt;There are a couple options for controlling access to data: Azure AD accounts/groups or Shared Access Signatures (SAS). Azure AD Groups provide a more manageable way to control Azure AD account access to data (than simply Azure AD accounts). SAS provides a granular means to provide delegate access to external entities.&lt;/p&gt;
&lt;h3 id="notable-information"&gt;Notable information &lt;!--TIL--&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LRS protects against rack-level hardware failure (so, if you want data-center-wide failure protection, LRS is insufficient).&lt;/li&gt;
&lt;li&gt;LRS is supported for Standard File and Standard Block Blob account types (otherwise, GRS is the default.)&lt;/li&gt;
&lt;li&gt;ZRS protects against data loss due to data center failure (so, if you want region-wide failure protection, ZRS is insufficient)&lt;/li&gt;
&lt;li&gt;GRS protects against region failure.&lt;/li&gt;
&lt;li&gt;GRS and GZRS secondary regions are pre-defined, forcing your data into a specific region.&lt;/li&gt;
&lt;li&gt;GZRS protects against region failure and simultaneous data center failure in the secondary region.&lt;/li&gt;
&lt;li&gt;When defining a data lifecycle, in the case of a tie, the option that results in the least cost will be chosen.&lt;/li&gt;
&lt;li&gt;Migrating from LRS to GRS is supported with a feature called &amp;quot;Live Migration.&amp;quot; Migration from LRS in other scenarios (e.g. to ZRS) must be done manually. Since Premium Storage accounts do not support LRS, Live Migration does not support Premium Storage accounts.&lt;/li&gt;
&lt;li&gt;Live migration supports the use case of a storage account failure of GRS-replicated data. GRS is a second LRS in a secondary region. If a region fails, GRS reduces to LRS, so recovering means using Live Migration.&lt;/li&gt;
&lt;li&gt;Durability is not backup; it provides access to data when infrastructure recoverability isn't an option. Apart from Live Migration, &lt;em&gt;restoration&lt;/em&gt; is limited to manually copying live data when needed.&lt;/li&gt;
&lt;li&gt;Durability does not protect against application-level failure; use backups or custom (application-level) durability in those scenarios.&lt;/li&gt;
&lt;li&gt;Encryption scopes are useful for providing logical data tenancy.&lt;/li&gt;
&lt;li&gt;Files added/modified in a File Share are only detected and replicated to the Windows Server file shares once every 24 hours (i.e., only visible after 24 hours).&lt;/li&gt;
&lt;li&gt;Adding a file share to a Sync Group acts like all the files and folders within the file share were just added, replicating to the cloud endpoint and any other file shares.&lt;/li&gt;
&lt;li&gt;When applying &lt;em&gt;least privilege&lt;/em&gt; to storage accounts, the &lt;strong&gt;Reader&lt;/strong&gt; role is also required on the Azure AD account if the Azure AD account needs to navigate storage resources in the Azure Portal.&lt;/li&gt;
&lt;li&gt;Asynchronous data redundancy options introduce the possibility of data loss. If the asynchronous duplication to the secondary region did not complete, it is out of sync with the last state of the primary region. Application-level logic is required to prevent loss of data in this scenario.&lt;/li&gt;
&lt;li&gt;The Archive tier does not have immediate access; it must be &lt;em&gt;rehydrated&lt;/em&gt; to a cool/hot tier first (usually with a Copy Blob operation of up to 15 hours completion time).&lt;/li&gt;
&lt;li&gt;File Share storage may be backed up to Recover Service vaults, but Blob Storage may not.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This table summarizes the types of storage accounts and the features/redundancy that each support.&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Account&lt;/th&gt;
&lt;th&gt;Redundancy&lt;/th&gt;
&lt;th style="text-align: center;"&gt;block blob&lt;/th&gt;
&lt;th style="text-align: center;"&gt;page blob&lt;/th&gt;
&lt;th style="text-align: center;"&gt;append blob&lt;/th&gt;
&lt;th style="text-align: center;"&gt;file share&lt;/th&gt;
&lt;th style="text-align: center;"&gt;queue&lt;/th&gt;
&lt;th style="text-align: center;"&gt;table&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Standard account&lt;/td&gt;
&lt;td&gt;LRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standard account&lt;/td&gt;
&lt;td&gt;GRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standard account&lt;/td&gt;
&lt;td&gt;GAZRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standard account&lt;/td&gt;
&lt;td&gt;RA-GZRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Premium Block blobs account&lt;/td&gt;
&lt;td&gt;LRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Premium Block blobs account&lt;/td&gt;
&lt;td&gt;ZRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Premium File shares account&lt;/td&gt;
&lt;td&gt;LRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Premium File shares account&lt;/td&gt;
&lt;td&gt;ZRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Premium Page blobs account&lt;/td&gt;
&lt;td&gt;LRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Premium Page blobs account&lt;/td&gt;
&lt;td&gt;ZRS&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☑&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;td style="text-align: center;"&gt;☐&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/DALL%C2%B7E-2022-12-22-17.03.40--distributed-cloud-data-storage-in-the-style-of-salvator-dali.png" class="img-fluid" alt="distributed cloud data storage"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/things-i-learned-attempting-azure-administrator-associate</id>
		<title>Things I Learned Attempting Azure Administrator Associate - Part 1</title>
		<link href="http://blog.peterritchie.com/posts/things-i-learned-attempting-azure-administrator-associate" />
		<updated>2022-12-20T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/DALL%C2%B7E-2022-12-20-15.03.33---A-woman-going-through-the-process-of-certifying-knowledge.png" class="img-fluid" alt="person going through the process of certifying knowledge" /&gt;&lt;/p&gt;
&lt;p&gt;I recently earned certification for Azure Administrator Associate.  My goal is to make my experience and skills more verifiable in areas like application solution architecture.  Azure Administrator Associate is a prerequisite for Azure Solutions Architect Expert and DevOps Engineer Expert (I imagine it's a prerequisite for all Azure * {Expert|Associate} certs.)&lt;/p&gt;
&lt;p&gt;Certifications aren't perfect, &amp;quot;certification&amp;quot; has different meanings to the observer and the certification itself. Most certifications bring with them an expected minimum understanding of the subject.  Does it mean the earner will do everything perfectly with the subject?  Of course not, but it gives the person a certain vocabulary to communicate more efficiently on the subject.&lt;/p&gt;
&lt;p&gt;The road to Azure Administrator Associate was interesting, and sharing some notable information would be helpful for others.&lt;/p&gt;
&lt;h2 id="making-the-implicit-explicit"&gt;Making The Implicit Explicit&lt;/h2&gt;
&lt;p&gt;The key to good communication is clearly understanding a subject and eliminating assumptions and misunderstandings. While understanding what is expected of a certified Azure Administrator Associate, I noticed some knowledge that I realized is typically implicit. Another way of looking at the following is that each starts with &amp;quot;It may seem obvious, but...&amp;quot;.&lt;/p&gt;
&lt;p&gt;Implicit knowledge is knowledge obtained through incidental activities; knowledge gained without awareness of learning is occurring.&lt;/p&gt;
&lt;h3 id="line-of-business-lob-applications"&gt;Line of Business (LoB) Applications&lt;/h3&gt;
&lt;p&gt;Line of Business (LoB) applications is ubiquitous in the computing industry.  Everyone knows what it &lt;em&gt;means&lt;/em&gt;, but if you ask two people to define it, you'll get more than one answer.  While agreement/standardization on what a LoB application is isn't going to happen any time soon, there are certain truths about LoB applications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An in-house, custom web application&lt;/li&gt;
&lt;li&gt;Not accessible via the Internet, either behind a firewall or strict access control (authentication and authorization)&lt;/li&gt;
&lt;li&gt;Access &lt;em&gt;may&lt;/em&gt; occur via an application gateway or load balancer&lt;/li&gt;
&lt;li&gt;Specific to the company, business area, or industry&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="azcopy"&gt;AzCopy&lt;/h3&gt;
&lt;p&gt;AzCopy works with Azure storage but only Azure Blob Storage and Azure Files.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There are many areas of clarification with Azure Administrator Associate.  Future posts on the subject will address clarifications involving important explicit limits, restrictions, constraints, rules, etc.&lt;/p&gt;
&lt;p&gt;Are there other implicit aspects of Azure administration that can be made explicit?&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/DALL%C2%B7E-2022-12-20-15.03.33---A-woman-going-through-the-process-of-certifying-knowledge.png" class="img-fluid" alt="person going through the process of certifying knowledge"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/fundamental-webapi-integration-tests</id>
		<title>Fundamental ASP.Net Minimal API Integration Tests</title>
		<link href="http://blog.peterritchie.com/posts/fundamental-webapi-integration-tests" />
		<updated>2022-11-03T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/robotic%20computing%20testing.png" class="img-fluid" alt="Robotic computing testing" /&gt;&lt;/p&gt;
&lt;p&gt;I've been involved with some fairly large projects that involved RESTful APIs. When dealing with multiple team members, multiple teams, and OpenAPI specs, there can be many risks. Even when an OpenAPI specification is generated from source code, what the code does can easily be unaligned with the spec. Luckily the spec is a machine-readable contract of the &lt;em&gt;intent and purpose&lt;/em&gt; of the API.&lt;/p&gt;
&lt;p&gt;Automated testing to the rescue! With ASP.NET, you can inject into and observe the middleware pipeline. ASP.NET integration tests are a common way of verifying the pipeline and how it is used. We can create integration tests that process the OpenAPI spec and verify operations are working as expected in various ways. This article dives into a couple of these ways.&lt;/p&gt;
&lt;h2 id="fundamental-api-integration-tests"&gt;Fundamental API Integration Tests&lt;/h2&gt;
&lt;p&gt;With a functioning Web API and an OpenAPI specification that describes it there are some fundamental things we can verify:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The generated OpenAPI document is valid&lt;/li&gt;
&lt;li&gt;The paths have endpoints implemented&lt;/li&gt;
&lt;li&gt;The operations respond with the correct type of response&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, let's set up our solution, projects, and integration testing scaffolding.&lt;/p&gt;
&lt;h2 id="setting-up-the-solution-and-projects"&gt;Setting Up the Solution and Projects&lt;/h2&gt;
&lt;p&gt;We're dealing with a Web API and integration tests, so let's create a Web API project and make the &lt;code&gt;Program&lt;/code&gt; class &lt;code&gt;public&lt;/code&gt;. You can do that manually in Visual Studio; but for consistency, the CLI is powerful (I'm being intentional with framework versions and some configuration options--appending &lt;code&gt;public partial class Program { }&lt;/code&gt; to Program.cs to make the class public):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;dotnet new solution
dotnet new webapi -o WebApi --use-minimal-apis true --framework net6.0 --use-program-main false
echo public partial class Program { } &amp;gt;&amp;gt; WebApi\Program.cs
dotnet sln add WebApi\WebApi.csproj
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we want to add a test project. xUnit is my go-to, so we'll use that and add a reference to the Web API project. Again, in the CLI:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;dotnet new xunit -o IntegrationTests --framework net6.0
del IntegrationTests\UnitTest1.cs
dotnet add IntegrationTests\IntegrationTests.csproj reference WebApi\WebApi.csproj
dotnet sln add IntegrationTests\IntegrationTests.csproj
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For ASP.Net integration tests, we will use &lt;code&gt;WebApplicationFactory&amp;lt;T&amp;gt;&lt;/code&gt;, which requires a reference to &lt;code&gt;Microsoft.AspNetCore.Mvc.Testing&lt;/code&gt;. In addition, to process OpenAPI documents, we'll need the &lt;code&gt;Microsoft.OpenApi.Readers&lt;/code&gt; package. Again, via the CLI:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;dotnet add IntegrationTests\IntegrationTests.csproj package Microsoft.OpenApi.Readers
dotnet add IntegrationTests\IntegrationTests.csproj package Microsoft.AspNetCore.Mvc.Testing
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="integration-test-scaffolding"&gt;Integration Test Scaffolding&lt;/h2&gt;
&lt;p&gt;I got into some of the scaffolding of ASP.NET 6 integration tests in &lt;a href="#setting-up-the-solution-and-projects"&gt;Setting Up the Solution and Projects&lt;/a&gt; concerning the required package references. the &lt;code&gt;Microsoft.AspNetCore.Mvc.Testing&lt;/code&gt; package is required so that we may use the &lt;a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.testing.webapplicationfactory-1?view=aspnetcore-6.0"&gt;&lt;code&gt;WebApplicationFactory&amp;lt;TEntryPoint&amp;gt;&lt;/code&gt;&lt;/a&gt; class--which allows us to bootstrap a web application in memory, specifically for testing.&lt;/p&gt;
&lt;p&gt;We'll use &lt;code&gt;WebApplicationFactory&lt;/code&gt; to create an instance of an &lt;code&gt;HttpClient&lt;/code&gt; test fake that works with our in-memory host. In addition, we'll override &lt;code&gt;WebApplicationFactory&lt;/code&gt; to get at some of the Swashbuckle details from the pipeline. We're interested in the generated OpenAPI document for processing and the name of that document to generate the OpenAPI specification URI for verification. Here's an example of a &lt;code&gt;WebApplicationFactory&lt;/code&gt; implementation that does what we need:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;public class MyWebApplicationFactory : WebApplicationFactory&amp;lt;Program&amp;gt;
{
	public OpenApiDocument? OpenApiDocument { get; private set; }
	public string OpenApiDocumentName { get; private set; } = string.Empty;

	protected override IHost CreateHost(IHostBuilder builder)
	{
		var host = base.CreateHost(builder);
		using var scope = host.Services.CreateScope();
		var sp = scope.ServiceProvider;
		var swaggerGeneratorOptions = sp.GetRequiredService&amp;lt;IOptions&amp;lt;SwaggerGeneratorOptions&amp;gt;&amp;gt;().Value;
		OpenApiDocumentName = swaggerGeneratorOptions.SwaggerDocs.First().Key ?? string.Empty;
		var swaggerProvider = sp.GetRequiredService&amp;lt;ISwaggerProvider&amp;gt;();
		OpenApiDocument = swaggerProvider.GetSwagger(OpenApiDocumentName);

		return host;
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The important parts are the &lt;code&gt;OpenApiDocument&lt;/code&gt; and &lt;code&gt;OpenApiDocumentName&lt;/code&gt; properties.&lt;/p&gt;
&lt;p&gt;Now that we've got integration testing scaffolded let's create a test base class to make creating multiple integration tests clean and tidy.&lt;/p&gt;
&lt;h2 id="some-test-conventions"&gt;Some Test Conventions&lt;/h2&gt;
&lt;p&gt;Automated testing classes and methods offer an opportunity to isolate and categorize tests to reduce work and clarify what is being tested (more importantly, what isn't passing). I tend towards a given/when/then structure when designing tests. The test class encapsulates the given/when (as well as the &lt;em&gt;arrange&lt;/em&gt; from arrange/act/assert) whose name is suffixed with &amp;quot;Should.&amp;quot; Each test method in the class is then given a name that describes the &lt;em&gt;then&lt;/em&gt; condition. I try to ensure that there is one condition and thus one assert per method. YMMV.&lt;/p&gt;
&lt;p&gt;For the tests I want to describe in this article, I've created a base class to encapsulate related given/when scenarios (or &lt;em&gt;shoulds&lt;/em&gt;) that require the details we're accessing with the &lt;code&gt;WebApplicationFactory&amp;lt;Program&amp;gt;&lt;/code&gt; implementation. Naming is hard, so I'm starting simple with a &lt;code&gt;WebApiShouldBase&lt;/code&gt; class that encapsulates the parts we're getting with &lt;code&gt;MyWebApplicationFactory&lt;/code&gt; and an ability to get a stream to the &amp;quot;live&amp;quot; OpenAPI spec document (JSON). It also deals with the responsibility of owning those things (e.g., disposal):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;public class WebApiShouldBase : IDisposable
{
	private readonly string openApiSpecUriText;

	protected readonly HttpClient WebApiClient;
	protected OpenApiDocument? OpenApiDocument { get; }
	protected Task&amp;lt;Stream&amp;gt; GetOpenApiDocumentStreamAsync() =&amp;gt; WebApiClient.GetStreamAsync(openApiSpecUriText);

	protected WebApiShouldBase()
	{
		var factory = new MyWebApplicationFactory();
		WebApiClient = factory.CreateClient();
		OpenApiDocument = factory.OpenApiDocument;
		this.openApiSpecUriText = $&amp;quot;/swagger/{factory.OpenApiDocumentName}/swagger.json&amp;quot;;
	}

	protected virtual void Dispose(bool isDisposing)
	{
		if (isDisposing)
		{
			Dispose();
		}
	}

	public void Dispose() =&amp;gt; WebApiClient.Dispose();

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The important parts are the &lt;code&gt;OpenApiDocument&lt;/code&gt; property which re-surfaces the &lt;code&gt;MyWebApplicationFactory.OpenApiDocument&lt;/code&gt; to implementors, the &lt;code&gt;WebApiClient&lt;/code&gt; property to access the API, and the &lt;code&gt;GetOpenApiDocumentStreamAsync&lt;/code&gt; method that holds the OpenAPI spec document that the API provides. This class hides things like the URI to the swagger.json, the use of &lt;code&gt;MyWebApplicationFactory&lt;/code&gt;, disposal, etc.&lt;/p&gt;
&lt;p&gt;With that, let's start doing some tests!&lt;/p&gt;
&lt;h2 id="verifying-the-generated-openapi-is-valid"&gt;Verifying The Generated OpenAPI Is Valid&lt;/h2&gt;
&lt;p&gt;&amp;quot;Valid&amp;quot; is subjective with OpenAPI. An OpenAPI spec is very &lt;em&gt;forgiving&lt;/em&gt; in allowing for many opinions on what a &lt;em&gt;good&lt;/em&gt; API looks like. I'm not going to go deep on what &lt;em&gt;good&lt;/em&gt; might mean; just dive into facilitating validation of that generated document. The fact that there is an OpenApiDocument instance, and a raw OpenAPI specification, is an implementation detail. We'll use that OpenApiDocument instance shortly, but I want to ensure that the raw document meets some minimum requirements. For this example, the OpenAPI document is processed, not errors we detected, and there &lt;em&gt;are&lt;/em&gt; paths. Very simple:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;	[Fact]
	public async Task ProduceValidOpenApi()
	{
		var readerResult = await new OpenApiStreamReader()
			.ReadAsync(await GetOpenApiDocumentStreamAsync().ConfigureAwait(false)).ConfigureAwait(false);
		Assert.NotNull(OpenApiDocument);
		Assert.NotEmpty(readerResult.OpenApiDocument.Paths);
		Assert.Empty(readerResult.OpenApiDiagnostic.Errors);
	}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Client requirements can be less strict than development requirements (development objectives), and there may be different subsets of requirements in the case of multiple clients. This example doesn't implement that specifically but does provide the means to do it (by adding distinct test methods.)&lt;/p&gt;
&lt;p&gt;OpenAPI.Net has can do very complex verification and validation, but I expect that sort of testing to be performed at a different level--I want to make sure client-oriented tests are handled here.&lt;/p&gt;
&lt;h2 id="verifying-the-paths-have-endpoints-implemented"&gt;Verifying The Paths Have Endpoints Implemented&lt;/h2&gt;
&lt;p&gt;Publishing an API with paths and operations, and hosting an API that hasn't implemented those operations is silly. So the next test verifies they are implemented (at least the GET operations) as specified:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;	[Fact]
	public async Task EndpointsRespondOkToGet()
	{
		Assert.NotNull(OpenApiDocument);
		var pathsWithGetOperations = OpenApiDocument.Paths.Where(w =&amp;gt; w.Value.Operations.ContainsKey(OperationType.Get));

		foreach (var (requestUriText, _) in pathsWithGetOperations)
		{
			var response = await WebApiClient.GetAsync(requestUriText).ConfigureAwait(false);
			Assert.True(response.IsSuccessStatusCode);
		}
	}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;GET operations are &lt;em&gt;easy&lt;/em&gt;; they shouldn't have a request body and almost always have a success response specified. In the future, I can dive into other types of operations like POST, how to extract samples from the OpenAPI specification, and how to verify operations with request data and or error responses.&lt;/p&gt;
&lt;h2 id="verifying-the-operations-respond-with-the-correct-type-of-response"&gt;Verifying The Operations Respond With The Correct Type Of Response&lt;/h2&gt;
&lt;p&gt;HTTP, and thus OpenAPI, don't enforce that any operation responds with anything in particular. But, if you're reading &lt;em&gt;this&lt;/em&gt; blog, you are probably of the opinion that given the opportunity to specify behavior, you should be at least as detailed in specifying the type and schema of the responses.  I'll leave out validating response schema in this article, but I will show verifying that each request responds with the correct media type. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;	[Fact]
	public async Task EndpointsRespondWithCorrectMediaTypeToGet()
	{
		Assert.NotNull(OpenApiDocument);
		var pathsWithGetOperations = OpenApiDocument.Paths.Where(w =&amp;gt; w.Value.Operations.ContainsKey(OperationType.Get));

		foreach (var (requestUriText, pathItem) in pathsWithGetOperations)
		{
			var responseContentType = pathItem.Operations[OperationType.Get]
				.Responses[OkResponseCodeText]
				.Content
				.Single().Key;

			var request = new HttpRequestMessage
			{
				Method = HttpMethod.Get,
				RequestUri = new Uri(requestUriText, UriKind.Relative),
				Headers =
				{
					{
						HttpRequestHeader.Accept.ToString(),
						responseContentType
					}
				}
			};
			var response = await WebApiClient.SendAsync(request).ConfigureAwait(false);
			Assert.True(response.Content.Headers.ContentType?.MediaType ==
			            responseContentType);
		}
	}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="caveats"&gt;Caveats&lt;/h2&gt;
&lt;p&gt;Of course, you can have or create an OpenAPI that does little more than document an endpoint and ignore that there are operations and those operations do specific things.&lt;/p&gt;
&lt;p&gt;This article is an overview. I recognize that Swashbuckle and &lt;del&gt;Swagger&lt;/del&gt;OpenAPI support in ASP.NET is powerful, but this article doesn't take into account many things you can do with it (like multiple OpenAPI documents.)&lt;/p&gt;
&lt;p&gt;I also recognize that operations that take no parameters are rare, but I trust that my readers are good with taking on that as an exercise. Or, at least let me know if that's detail I should post in the future.&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;This article provides a very high-level overview of integration testing ASP.NET minimal APIs. We then got into some details of general Web API integration tests that focus on OpenAPI specification aspects of the Web API middleware.&lt;/p&gt;
&lt;p&gt;What sort of automated testing of an API specification do you see as beneficial to your projects?&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/aspnet/core/test/integration-tests?view=aspnetcore-6.0"&gt;Integration tests in ASP.NET Core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.testing.webapplicationfactory-1?view=aspnetcore-6.0"&gt;&lt;code&gt;WebApplicationFactory&amp;lt;TEntryPoint&amp;gt;&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The source for the examples, including the creation scripts can be found at &lt;a href="https://github.com/peteraritchie/fundamental-webapi-integration-testing"&gt;https://github.com/peteraritchie/fundamental-webapi-integration-testing&lt;/a&gt;&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/robotic%20computing%20testing.png" class="img-fluid" alt="Robotic computing testing"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/visual-studio-defender-performance</id>
		<title>Visual Studio Performance with Microsoft Defender</title>
		<link href="http://blog.peterritchie.com/posts/visual-studio-defender-performance" />
		<updated>2022-10-27T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/antivirus%20exclusion%20developer.png" class="img-fluid" alt="Antivirus Exclusion Developer Dall-E image" /&gt;&lt;/p&gt;
&lt;p&gt;Steve Smith posted about &lt;a href="https://ardalis.com/speed-up-visual-studio-build-times/?utm_sq=h3m43zzlkm"&gt;speeding up built times in Visual Studio&lt;/a&gt; by configuring Windows Defender.  That was in 2016 and to say things have changed a bit is probably an understatement.  Configuring a new laptop, I thought I'd revisit this briefly.&lt;/p&gt;
&lt;p&gt;Before changing anything in Windows Virus &amp;amp; Threat Protection, go ahead and run a scan to make sure we're starting with a clean slate.  &lt;del&gt;Go to &lt;a href="ms-settings:windowsdefender"&gt;Windows Security&lt;/a&gt; and click &lt;strong&gt;Virus &amp;amp; threat protection&lt;/strong&gt; then click the &lt;strong&gt;Quick scan&lt;/strong&gt; button.&lt;/del&gt; I've been advocating scripting all-the-things, to run a quick scan in an administrator Powershell terminal run &lt;code&gt;Start-MpScan -ScanType QuickScan&lt;/code&gt;.  You can also run a full-scan, if that makes you more comfortable: &lt;code&gt;Start-MpScan -ScanType FullScan&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once that's complete we can configure Windows Virus and Threat Protection to &amp;quot;trust&amp;quot; (exclude) Visual Studio.  To do that in PowerShell you can use the &lt;a href="https://learn.microsoft.com/en-us/powershell/module/defender/add-mppreference?view=windowsserver2022-ps"&gt;&lt;code&gt;App-MpPreference&lt;/code&gt; cmdlet&lt;/a&gt; (as well as see what's already configured with the &lt;a href="https://learn.microsoft.com/en-us/powershell/module/defender/get-mppreference?view=windowsserver2022-ps"&gt;&lt;code&gt;Get-MpPreference&lt;/code&gt; cmdlet&lt;/a&gt;).  Some examples:&lt;/p&gt;
&lt;p&gt;With Visual Studio 2022 Enterprise:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionProcess &amp;quot;$Env:ProgramFiles\Microsoft Visual Studio\2022\Enterprise\Common7\IDE\devenv.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With Visual Studio 2022 Professional:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionProcess &amp;quot;$Env:ProgramFiles\Microsoft Visual Studio\2022\Professional\Common7\IDE\devenv.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With Visual Studio 2022 Community:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionProcess &amp;quot;$Env:ProgramFiles\Microsoft Visual Studio\2022\Community\Common7\IDE\devenv.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And, with Visual Studio 2022 Preview:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionProcess &amp;quot;$Env:ProgramFiles\Microsoft Visual Studio\2022\Preview\Common7\IDE\devenv.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also do that for Visual Studio Code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionProcess &amp;quot;$Env:LocalAppData\Programs\Microsoft VS Code\code.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also exclude the location of where you store your source code.  The default location is &lt;code&gt;C:\Users\&amp;lt;user-name&amp;gt;\source\repos&lt;/code&gt; for Visual Studio.  So, in PowerShell, you can add a path exclusion:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionPath &amp;quot;$Env:USERPROFILE\source\repos&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Note:&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;If you're working with Git repositories that you're unsure of what they contain, you may want to separate where you clone those repos from where you exclude.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Or, if you want a PowerShell script to just do all thee things, see &lt;a href="https://gist.githubusercontent.com/peteraritchie/d6025591566821b4ae5995eb831b6e8d/raw/912b5b20b749d506562437f40e169e6a3e24d279/optimize-defender.ps1"&gt;optimize-defender.ps1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other processes to consider:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-PowerShell"&gt;Add-MpPreference -ExclusionProcess &amp;quot;$Env:ProgramFiles\dotnet\dotnet.exe&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any other processes or paths that you'd consider for exclusion?&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/antivirus%20exclusion%20developer.png" class="img-fluid" alt="Antivirus Exclusion Developer Dall-E image"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/By-Reference-in-csharp</id>
		<title>By Reference in C#</title>
		<link href="http://blog.peterritchie.com/posts/By-Reference-in-csharp" />
		<updated>2022-09-28T00:00:00Z</updated>
		<content>&lt;p&gt;I became aware recently that there were many C# compiler errors that do not have a corresponding documentation page.  That documentation is open-source and I chose to spend some time contributing some pages for the community. Looking at a language feature from the perspective of its compile-time errors is rather enlightening, so I'd though I'd write a bit about these features in hopes of offering a better understanding for my readers.&lt;/p&gt;
&lt;p&gt;C# compiler errors can be categorized (arbitrarily) by different areas of C# syntax, and I started to focus on one category at a time.  One of those areas involves referenced variables.  C# has always has &lt;code&gt;ref&lt;/code&gt; arguments, but &lt;code&gt;ref&lt;/code&gt; return, &lt;code&gt;ref&lt;/code&gt; locals, &lt;code&gt;ref&lt;/code&gt; structs, and &lt;code&gt;ref&lt;/code&gt; fields have been additions to the syntax.&lt;/p&gt;
&lt;p&gt;The declaration of a variable in C# influences its syntax in a couple ways: binding and accessibility.  Accessibility is whether an identifier is &lt;em&gt;visible&lt;/em&gt; at compile-time in a given context.  Binding is how an identifier or name is bound at run-time to resources like data and code.  Binding uniquely affect the compile-time correctness of any particular usage of a &lt;code&gt;ref&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;Binding affects the compile-time usage of an identifier because of the run-time lifetime of the resources it is bound to. You're probably familiar with a static method accessing instance data and the errors caused in this context. &lt;code&gt;ref&lt;/code&gt; variables have a similar context when they are stack allocated. Heap-allocated objects (objects bound to the heap) can have their lifetime extended to be long-lived because the heap shares the same lifetime as the application. Variables bound to stack-allocated resources cannot have their lifetime extended beyond a specific scope. The stack is a sequential collection of elements with elements implicitly partitioned by a shared scope. The most recognized scope is probably a method call or method/lambda body. Local variables bound to stack elements do not have a lifetime beyond the method call. A reference to a stack object cannot be assigned to a variable or expression with a broader scope.&lt;/p&gt;
&lt;p&gt;How far the value of an expression can leave the confines of its declaration scope is called &amp;quot;escape scope&amp;quot;.  Sometimes the escape scope is the same as the declaration scope.  The compiler verifies compatible escape scopes during assignment.  For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;    void M(ref int ra)
    {
        int number = 0;
        ref int rl = ref number;
        if (ra == 0)
        {
            int x = number;
            rl = ref x;
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;x&lt;/code&gt; is local to the &lt;code&gt;if&lt;/code&gt; body, it is bound to the stack, and its escape scope is narrower than &lt;code&gt;ref rl&lt;/code&gt; because &lt;code&gt;ref rl&lt;/code&gt; is declared in the outer scope.  Since &lt;code&gt;ref rl&lt;/code&gt; is an alias to another variable, it cannot reference a variable bound to a resource that will go out of scope before it does.  &lt;code&gt;rl = ref x&lt;/code&gt; results in a compiler error.  If &lt;code&gt;rl&lt;/code&gt; were not a reference to a value type, the assignment would be okay because &lt;code&gt;x&lt;/code&gt; would be bound to heap and have a broader escape scope.&lt;/p&gt;
&lt;p&gt;The compiler also verifies compatible escape scopes when returning values.  For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;    ref int M(ref int ra)
    {
        int number = 0;
        ref int rl = ref number;
        if (ra == 0)
        {
            ref int x = ref number;
            return ref x;
        }
        return ref ra;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;return ref x&lt;/code&gt; results in a compiler error because the escape scope of &lt;code&gt;x&lt;/code&gt; is local to the method.  The error message here may not be as clear as the first because it doesn't mention the narrower escape scope.&lt;/p&gt;
&lt;p&gt;There are the basic escape scopes.  A calling method scope, a current method scope, and a return-only scope.&lt;/p&gt;
&lt;p&gt;The calling method scope is a scope outside of the containing method/lambda.  References can reach this scope via either a &lt;code&gt;ref&lt;/code&gt; parameter or a return.&lt;/p&gt;
&lt;p&gt;The current method scope is a scope within a containing method/lambda.&lt;/p&gt;
&lt;p&gt;The return-only scope is a special case for &lt;code&gt;ref struct&lt;/code&gt; types that can only leave the method scope via a return and not through a &lt;code&gt;ref&lt;/code&gt; or &lt;code&gt;out&lt;/code&gt; parameter.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;I became aware recently that there were many C# compiler errors that do not have a corresponding documentation page.  That documentation is open-source and I chose to spend some time contributing some pages for the community. Looking at a language feature from the perspective of its compile-time errors is rather enlightening, so I'd though I'd write a bit about these features in hopes of offering a better understanding for my readers.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/the-fundamental-quality-attributes-of-technology-systems</id>
		<title>Fundamental Quality Attributes of Technology Systems</title>
		<link href="http://blog.peterritchie.com/posts/the-fundamental-quality-attributes-of-technology-systems" />
		<updated>2022-09-16T00:00:00Z</updated>
		<content>&lt;p&gt;What are quality attributes? The term &amp;quot;non-functional requirements&amp;quot; has been more prevalent, but that is a technologist's term. The first time you bring up &amp;quot;non-functional requirements&amp;quot; with a customer, there's always confusion, then concern. I've heard more than once, &amp;quot;we want something functional.&amp;quot;&lt;/p&gt;
&lt;p&gt;The most important attribute of a system is its functionality. Functionality is whether a system is &lt;em&gt;fit for purpose&lt;/em&gt;. A system's functionality is what makes it unique, so I'll defer detail on functional attributes for another time. In this post I'll focus this post on cross-cutting quality attributes that permeate all aspects of a solution.&lt;/p&gt;
&lt;p&gt;Quality attributes are the characteristics a system needs to exhibit--qualifications of the system's desired functionality. Quality attributes address customer concerns regarding the degree of success of a system. A customer's concerns of a system are unique and thus precludes having a universal prioritized list of quality attributes.&lt;/p&gt;
&lt;p&gt;It is simple to describe the characteristics a customer expects of a system that provides the features they need:  Customers expect features that operate without fault or error, operate consistently within expectations, operate within resource constraints, and protect from unauthorized access. Translating that into a collection of system-specific measures is an enormous undertaking that cannot be taken lightly.&lt;/p&gt;
&lt;p&gt;Many philosophies about quality attributes (usually termed &amp;quot;quality models&amp;quot;) exist, like FURPS, ISO/IEC 9126/25010, McCall, etc. These models detail several categories that organize the many adjectives that can apply to software systems. Some common categories may include Reliable, Efficient, Maintainable, Secure, etc. I view quality attributes as a palette of possible adjectives; no one list is perfect for every situation. There are top-/high-level categorizations that can apply more broadly. When discussing quality attributes, we use the noun form (Reliability vs. Reliable.) I've landed on the following top-level categories (in no particular order): Performance, Operability, Security, and Dependability.&lt;/p&gt;
&lt;h2 id="dependability-of-features"&gt;Dependability (of features)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;to function, without fault or error&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dependability involves concerns such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;availability — readiness for usage&lt;/li&gt;
&lt;li&gt;reliability — continuity of service&lt;/li&gt;
&lt;li&gt;safety — non-occurrence of catastrophic consequences on the environment&lt;/li&gt;
&lt;li&gt;confidentiality — non-occurrence of unauthorized disclosure of information&lt;/li&gt;
&lt;li&gt;integrity — non-occurrence of improper alterations of information&lt;/li&gt;
&lt;li&gt;maintainability — aptitude to undergo repairs and evolution&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="performance-of-execution"&gt;Performance (of execution)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;To function within resource constraints (time, compute, storage, memory, network) constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Performance involves concerns such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;latency - the degree of responsiveness.&lt;/li&gt;
&lt;li&gt;throughput - the rate at which work can be performed&lt;/li&gt;
&lt;li&gt;capacity - the amount of work that can be performed&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="operability-of-function"&gt;Operability (of function)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;to become and remain operable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operability involves concerns such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;deployability - the ability of a system to be put into production&lt;/li&gt;
&lt;li&gt;monitorability - the ability of a system's health and operation to be monitored&lt;/li&gt;
&lt;li&gt;configurability - the ability of a system's behavior to be customized&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="security"&gt;Security&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;To ensure authorized usage.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Security involves concerns such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Confidentiality - the quality of a system restrict access to information&lt;/li&gt;
&lt;li&gt;Integrity - the quality of a system adhere to accuracy and consistency of information and behavior&lt;/li&gt;
&lt;li&gt;Availability - the quality of a system to provide access to information to those authorized&lt;/li&gt;
&lt;li&gt;accountability - the quality of a system to account for its actions when fulfilling its responsibilities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because quality attributes address customer concerns, there are overlaps between categories. For example, there's a dependability concern that data integrity does not impact functionality; there's also a security concern that data integrity doesn't result in data loss. Don't let the overlap distract you from what's best for your solution. It will change even if you could pre-define a complex structure of quality attributes most suitable for your solution. Needs change, priorities change, and quality attributes are philosophic influencers to a solution that requires nurturing.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;What are quality attributes? The term "non-functional requirements" has been more prevalent, but that is a technologist's term. The first time you bring up "non-functional requirements" with a customer, there's always confusion, then concern. I've heard more than once, "we want something functional."&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/naming-things-events-and-action</id>
		<title>Naming Things - Common Actions and Events</title>
		<link href="http://blog.peterritchie.com/posts/naming-things-events-and-action" />
		<updated>2022-09-01T00:00:00Z</updated>
		<content>&lt;p&gt;In this multi-part series on Naming Things, I dig into the benefits of having a clear understanding of common terms and concepts--in this case, common actions and events.&lt;/p&gt;
&lt;p&gt;What does Deleted mean? Is it the same as Removed or Destroyed? What if you want to support soft delete as well as hard delete?&lt;/p&gt;
&lt;p&gt;I want to be clear; these aren't developer decisions. They're developer problems based on a lack of clarity in the customer's domain. A customer likely won't use terms like &amp;quot;soft delete&amp;quot; and &amp;quot;hard delete .&amp;quot;The customer will probably refer to the most common form of delete as &amp;quot;delete.&amp;quot; An architect role is responsible for teasing out the nuances of meaning into terms that the subject matter experts agree upon and getting consensus on usage with the development team.&lt;/p&gt;
&lt;p&gt;Every system involves mutating data and information, yet it can be a common source of confusion regarding naming things. There are multiple types of data changes. Systems can create new data and may add that new data to a collection--physical or logical. Systems may change data, or designers may change the structure of data. Data is often removed--from a particular view or existence.&lt;/p&gt;
&lt;p&gt;English allows us to reuse terms to mean many things. &amp;quot;Delete&amp;quot; and &amp;quot;changed,&amp;quot; for example. There are well-known terms that enable us to communicate intent and consequences easily. But, when we reuse these terms across different contexts with different intents and consequences, we introduce the possibility of confusion, making naming things seem difficult.&lt;/p&gt;
&lt;p&gt;It's important to understand the different intents and resulting consequences to data and attempt to get consensus on names and terms that adequately and uniquely represent these situations.&lt;/p&gt;
&lt;p&gt;&amp;quot;Delete&amp;quot; is a common point of confusion. There may be a need for &lt;em&gt;soft deletes&lt;/em&gt; and &lt;em&gt;hard deletes&lt;/em&gt;; both of WHICH make data inaccessible in a context. But, data may also be moved from one context to another, changing its accessibility but not making it &lt;em&gt;inaccessible&lt;/em&gt;. To use a single term like &amp;quot;delete&amp;quot; for all of these situations leads to confusion and issues in naming things.&lt;/p&gt;
&lt;!--
An important aspect of naming: name the consistency boundary. What is a date? A year, month, and day. If we included time, is it still a date? Typically that would be called date/time.  
--&gt;
&lt;p&gt;Each domain can be different, but the situations I've just described are very common. For those, I start with unique terms for each and work with the subject matter experts to refine them (if needed):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Deleted&lt;/strong&gt; means something is no longer accessible in some context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destroyed&lt;/strong&gt; means removed from existence; no possible way to ever get it back.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Removed&lt;/strong&gt; means a thing has been moved out of or removed from a container/collection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Inverse terms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Created&lt;/strong&gt; signifies something new has come into existence (rather than Added).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Added&lt;/strong&gt;* signifies something has been added to a container or collection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mutating information seems like such a simple concept. But, we often need to know if data changes within the context of other data.  Unique data mutation terms I start out with when working with subject matter experts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Updated&lt;/strong&gt; signifies the value properties or attributes of an existing thing (entity) have been changed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Changed&lt;/strong&gt; signifies an entire thing (entity) has been replaced with another.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="word-form"&gt;Word Form&lt;/h2&gt;
&lt;p&gt;Actions are verbs, and events are past participles constructed from verbs. Most event names are constructed from regular verbs by adding the prefix -ed. Delete + ed: deleted; create + ed: created.  Sometimes events are constructed from irregular verbs and don't end in ed. Bind: bound; drive: driven; sleep: slept.&lt;/p&gt;
&lt;p&gt;Events are not simply verbs in past tense form. An event's context is that it is related to a subject. For example, the event &amp;quot;deleted&amp;quot; involves a subject and is used to describe the current state as a result of a past action. In grammar, this is &lt;em&gt;present perfect tense&lt;/em&gt; and implies an auxiliary verb of &amp;quot;has been .&amp;quot;e.g., &lt;em&gt;The customer record has been deleted&lt;/em&gt; or &lt;em&gt;The customer record is deleted&lt;/em&gt;. Since this details the subject somehow, it is also in a &lt;em&gt;present indicative&lt;/em&gt; form. This detail is important but normally for edge cases. Normal domain narratives should align with this because that's normal language in these scenarios.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Match events to actions; don't define events when no action would result in that event.&lt;/li&gt;
&lt;li&gt;Don't assume events always end in &amp;quot;ed.&amp;quot;&lt;/li&gt;
&lt;li&gt;Events are present indicative, past participles, and in the present perfect tense.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Do you have other actions and events that you commonly encounter?&lt;/p&gt;
</content>
		<summary>&lt;p&gt;In this multi-part series on Naming Things, I dig into the benefits of having a clear understanding of common terms and concepts--in this case, common actions and events.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Message-oriented-Minimal-APIs-in-ASP.NET</id>
		<title>Message-oriented Minimal APIs in ASP.NET Core</title>
		<link href="http://blog.peterritchie.com/posts/Message-oriented-Minimal-APIs-in-ASP.NET" />
		<updated>2022-08-28T00:00:00Z</updated>
		<content>&lt;p&gt;TL;DR - &lt;a href="#implementation-details"&gt;go to the implementation details&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;First of all, what is message-oriented?  Like many things in technology and life, terms like &amp;quot;oriented&amp;quot; are frequently used whose meaning may not be immediately connected to its usage.  Object-oriented, message-oriented, aspect-oriented, etc. have a vague meaning when used, which can sometimes introduce a lack of clarity.&lt;/p&gt;
&lt;p&gt;*-Oriented means that a particular concept always taken into consideration and utilized in the specified circumstances.  Message-oriented means that interactions between concepts &lt;em&gt;at a certain layer&lt;/em&gt; involve messages.  This is sometimes referred to as Message Passing; or that communication between layer-specific concepts it done by passing messages to each other.&lt;/p&gt;
&lt;p&gt;Things can be oriented in many ways at the same time.  A system may be simultaneously message-oriented and object-oriented, for example--which usually means that what produces and consumes messages are implemented as &lt;em&gt;objects&lt;/em&gt;.&lt;/p&gt;
&lt;!--Some may say that the Command Pattern is message-oriented.  For the purposes of this article, that's not the complete story.  A command can (and should) be a message; but a message on it's own does not constitute message-orientation.  Falling back to Message Passing, it's how the command is communicated is what makes a component message-oriented.

## Is HTTP Message-Oriented?

Yes, HTTP is message-oriented.  Underlying layers (like TCP) implement HTTP via frames and streams (and packets, datagrams, etc.) but at the HTTP layer, communication between major concepts is done with what is called "messages".
--&gt;
&lt;h2 id="being-message-oriented"&gt;Being Message-Oriented&lt;/h2&gt;
&lt;p&gt;Message-orientation demands a level of loose coupling.  In object-oriented message-orientation objects donn't communicate with each other directly, a third-party transports message from the sender (or producer) to the receiver (or the consumer).  There an many ways that can happen: queues (or simply collections), mediators, buses, etc.  The type of the third-party component depends on the degree of loose coupling and how much work the third party takes on to transport those messages.  For the purposes of this article I'll focus on &lt;em&gt;Bus Architecture&lt;/em&gt;.  Bus Architecture is a combination of a common data model, a common command set, and an infrastructure that provides a shared set of interfaces to transport messages.&lt;/p&gt;
&lt;h2 id="being-successfully-message-oriented"&gt;Being Successfully Message-Oriented&lt;/h2&gt;
&lt;p&gt;As with any layered architecture, implementation details at different layers allow us to compartmentalize different concerns to ease understanding and simplify implementation.  Message-oriented systems often classify messages to better implement and support a subdomain.  Messages are often classified as commands, events, or documents to better support common subdomain and communication scenarios.  Commands are messages that communicate a request or imperative intent.  Events are messages that communicate or encapsulate a change in state.  And documents are messages that contain data independent of a command or an event.&lt;/p&gt;
&lt;h2 id="why-minimal-apis"&gt;Why Minimal APIs?&lt;/h2&gt;
&lt;p&gt;You may have read articles like &amp;quot;&lt;a href="https://ardalis.com/mvc-controllers-are-dinosaurs-embrace-api-endpoints/"&gt;MVC Controllers are Dinosaurs - Embrace API Endpoints&lt;/a&gt;&amp;quot; that suggest that modern MVC implementation have controllers that don't actually &amp;quot;control&amp;quot; anything.  MVC details that Models, Views, and Controllers are decoupled from one another and cohesive in and of themselves.  Controllers should interpret input and convert it into invocations upon the model and the view.  Models are a dynamic data structure that directly manages data, logic, and rules for a given context.  When MVC was devised, the controller was far closer to the user and took on more responsibility to imperatively translate and route data.  With modern systems and technologies like JSON and programming language syntax, much of that translation and routing can be declarative--wiring up a request, its route, and the receiver of the command directly.&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;As an aside, many have argued that &lt;em&gt;model&lt;/em&gt; and &lt;em&gt;view&lt;/em&gt; have been muddied and that &lt;em&gt;view&lt;/em&gt; doesn't exist with RESTful APIs, questioning &amp;quot;MVC&amp;quot; implementations altogether.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;p&gt;When you don't really have a controller and data translation occurs under the hood, going through the motions of controllers and models with core subdomain objects is viewed as needless ceremony.&lt;/p&gt;
&lt;h2 id="message-oriented-frameworks"&gt;Message-Oriented Frameworks&lt;/h2&gt;
&lt;p&gt;I've been working with a simple-but-no-simpler messaging library for several years.  It's a set of libraries that I maintain called &lt;code&gt;[PRI.Messaging](https://github.com/peteraritchie/Messaging)&lt;/code&gt;.  It consists of primitive types (abstractions) (&lt;code&gt;PRI.Messaging.Primitives&lt;/code&gt;) and pattern implementations (&lt;code&gt;PRI.Messaging.Patterns&lt;/code&gt;).  It makes ideas like consumers, producers, and buses first-class concepts.  PRI.Messaging.Patterns includes a bus implementation that assumes the role of dependency injection and message routing, allowing you to simply create message producers, message consumers, and have them automatically wired-up and messages routed appropriately.&lt;/p&gt;
&lt;p&gt;I'll be using these libraries to implement message-oriented minimal APIs in ASP.NET Core 6+.&lt;/p&gt;
&lt;h2 id="implementation-details"&gt;Implementation Details&lt;/h2&gt;
&lt;p&gt;For simplicity, I'll show making the default project created for minimal APIs message-oriented; get ready for some weather forecasting.&lt;/p&gt;
&lt;p&gt;Starting with creating the default project:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;dotnet new webapi -minimal -o WebApi
dotnet new sln -n example
dotnet sln example.sln add WebApi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This gives us OpenAPI (Swagger) and HTTPs support along with a single &lt;code&gt;weatherforecast&lt;/code&gt; endpoint and a &lt;code&gt;WeatherForecast&lt;/code&gt; response model (message).&lt;/p&gt;
&lt;p&gt;The important code from Program.cs:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;var summaries = new[]
{
    &amp;quot;Freezing&amp;quot;, &amp;quot;Bracing&amp;quot;, &amp;quot;Chilly&amp;quot;, &amp;quot;Cool&amp;quot;, &amp;quot;Mild&amp;quot;, &amp;quot;Warm&amp;quot;, &amp;quot;Balmy&amp;quot;, &amp;quot;Hot&amp;quot;, &amp;quot;Sweltering&amp;quot;, &amp;quot;Scorching&amp;quot;
};

app.MapGet(&amp;quot;/weatherforecast&amp;quot;, () =&amp;gt;
{
    var forecast =  Enumerable.Range(1, 5).Select(index =&amp;gt;
        new WeatherForecast
        (
            DateOnly.FromDateTime(DateTime.Now.AddDays(index)),
            Random.Shared.Next(-20, 55),
            summaries[Random.Shared.Next(summaries.Length)]
        ))
        .ToArray();
    return forecast;
})
.WithName(&amp;quot;GetWeatherForecast&amp;quot;)
.WithOpenApi();

app.Run();

record WeatherForecast(DateOnly Date, int TemperatureC, string? Summary)
{
    public int TemperatureF =&amp;gt; 32 + (int)(TemperatureC / 0.5556);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To become message-oriented we need to first create explicit messages to represent the interactions.  For this I've created a &lt;code&gt;GetWeatherForecastCommand&lt;/code&gt; command and a &lt;code&gt;WeatherForecastedEvent&lt;/code&gt; event:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;public class GetWeatherForecastCommand : ICommand
{
    public string CorrelationId { get; set; } = Guid.NewGuid().ToString();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;public class WeatherForecastedEvent : IEvent
{
    public WeatherForecast[] Forecasts { get; }

    public WeatherForecastedEvent(WeatherForecast[] forecasts)
    {
        Forecasts = forecasts;
    }

    public DateTime OccurredDateTime { get; set; } = DateTime.UtcNow;
    public string CorrelationId { get; set; } = Guid.NewGuid().ToString();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we need something that explicitly handles (consumes) the &lt;code&gt;GetWeatherForecastCommand&lt;/code&gt; command produces the &lt;code&gt;WeatherForecastedEvent&lt;/code&gt; event.  I prefer to call these types of things &amp;quot;Command Handlers&amp;quot;.  So,:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;public class GetWeatherForecastCommandHandler : IConsumer&amp;lt;GetWeatherForecastCommand&amp;gt;, IProducer&amp;lt;WeatherForecastedEvent&amp;gt;
{
    private IConsumer&amp;lt;WeatherForecastedEvent&amp;gt; consumer = new ActionConsumer&amp;lt;WeatherForecastedEvent&amp;gt;((_) =&amp;gt; { });

    public void AttachConsumer(IConsumer&amp;lt;WeatherForecastedEvent&amp;gt; consumer)
    {
        this.consumer = consumer;
    }

    private readonly string[] summaries = new[]
    {
        &amp;quot;Freezing&amp;quot;, &amp;quot;Bracing&amp;quot;, &amp;quot;Chilly&amp;quot;, &amp;quot;Cool&amp;quot;, &amp;quot;Mild&amp;quot;, &amp;quot;Warm&amp;quot;, &amp;quot;Balmy&amp;quot;, &amp;quot;Hot&amp;quot;, &amp;quot;Sweltering&amp;quot;, &amp;quot;Scorching&amp;quot;
    };

    public void Handle(GetWeatherForecastCommand message)
    {
        var forecasts = Enumerable.Range(1, 5).Select(index =&amp;gt;
            new WeatherForecast
            (
                DateTime.Now.AddDays(index),
                Random.Shared.Next(-20, 55),
                summaries[Random.Shared.Next(summaries.Length)]
            ))
            .ToArray();

        consumer.Handle(new WeatherForecastedEvent(forecasts));
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you'll see in this command handler, I've moved the implementation details from Program.cs and encapsulated them into this class (i.e. &lt;code&gt;summaries&lt;/code&gt; and the creation of the &lt;code&gt;WeatherForcast&lt;/code&gt; array.)&lt;/p&gt;
&lt;p&gt;Returning to Program.cs, we now need to inject a &lt;code&gt;Bus&lt;/code&gt; service and update the route endpoint to accept a bus instance, translate to our command, and send it to the bus.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;app.MapGet(&amp;quot;/weatherforecast&amp;quot;, async (IBus bus) =&amp;gt;
{
    WeatherForecastedEvent result =
        await bus.RequestAsync&amp;lt;GetWeatherForecastCommand, WeatherForecastedEvent&amp;gt;(
            new GetWeatherForecastCommand());
    return Results.Ok(result.Forecasts);
})
.WithName(&amp;quot;GetWeatherForecast&amp;quot;)
.WithOpenApi();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;IBus&lt;/code&gt; &lt;code&gt;RequestAsync&lt;/code&gt; extension method implements the asynchronous request-reply pattern.&lt;/p&gt;
&lt;p&gt;With our messages, consumers, and producers we can now create a message bus singleton and have it wire-up the producers and the consumers.  This is simply done by invoking the &lt;code&gt;IBus.AddHandlersAndTranslators&lt;/code&gt; method in addition to registering a singleton bus:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;IBus bus = new Bus();
bus.AddHandlersAndTranslators(
    Path.GetDirectoryName(typeof(Program).Assembly.Location)!,
    Path.GetFileName(typeof(Program).Assembly.Location), &amp;quot;&amp;quot;);
builder.Services.AddSingleton(bus);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;As you can see, the route endpoint has an &lt;code&gt;IBus&lt;/code&gt; injected into it (i.e. Dependency Injection) and is only concerned with sending a &lt;code&gt;GetWeatherForecastCommand&lt;/code&gt; message and receiving a &lt;code&gt;WeatherForecastedEvent&lt;/code&gt; message. Where that command goes and where the event comes from (and how it gets created) are irrelevant (i.e. neither knows nor cares about &lt;code&gt;GetWeatherForecastCommandHandler&lt;/code&gt;).  With the implementation details of weather forecasting moved out into &lt;code&gt;GetWeatherForecastCommandHandler&lt;/code&gt; those details are now longer directly coupled to a web API.  &lt;code&gt;GetWeatherForecastCommandHandler&lt;/code&gt; exists in its own library and can be used by several types of applications.  &lt;code&gt;GetWeatherForecastCommandHandler&lt;/code&gt; could be used, as is, within a console application, a PowerShell CmdLet, etc.  As with any well designed loosely coupled system, it's just a matter of correctly setting up a service container for the specific circumstances.&lt;/p&gt;
&lt;p&gt;How will you use event-orientation?&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ardalis.com/mvc-controllers-are-dinosaurs-embrace-api-endpoints/"&gt;MVC Controllers are Dinosaurs - Embrace API Endpoints | Ardalis Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/peteraritchie/Messaging"&gt;PRI.Messaging - GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/PRI.Messaging.Primitives/3.0.0-beta"&gt;PRI.Messaging.Primitives - Nuget&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/PRI.Messaging.Patterns/3.0.0-beta"&gt;PRI.Messaging.Patterns - Nuget&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/async-request-reply"&gt;Asynchronous Request-Reply Pattern - Azure Architecture Center&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.enterpriseintegrationpatterns.com/RequestReply.html"&gt;Request-Reply Messaging Pattern - Enterprise Integration Patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
		<summary>&lt;p&gt;TL;DR - &lt;a href="#implementation-details"&gt;go to the implementation details&lt;/a&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/data-urls-in-markdown</id>
		<title> Data URLs in Markdown</title>
		<link href="http://blog.peterritchie.com/posts/data-urls-in-markdown" />
		<updated>2022-06-27T00:00:00Z</updated>
		<content>&lt;ul&gt;
&lt;li&gt;Data URLs embed data within the URI instead of being a link&lt;/li&gt;
&lt;li&gt;Data URLs can be used to embed images into a web page&lt;/li&gt;
&lt;li&gt;Data URLs can be used for images in markdown&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="#data-urls"&gt;TL;DR&lt;/a&gt;⮷&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;h3 id="links-in-markdown"&gt;Links in Markdown&lt;/h3&gt;
&lt;p&gt;URLs can be used in markdown as a hyper-link to another location (another page, or an anchor in the current page, or both.) These links in markdown come in two varieties: &amp;quot;conventional&amp;quot; and reference-style.  Conventional links have the format &lt;code&gt;[text](url)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Reference-style links have a two-part format.  The first is the reference declaration which consists of a name and the URL.  For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-markdown"&gt;[twitter]: https://twitter.com/peterritchie
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Typically the reference declarations appear at the end of the markdown file.&lt;/p&gt;
&lt;p&gt;That second-part of the format is slightly different than a conventional link: &lt;code&gt;[Visible Text][reference-name]&lt;/code&gt; (notice that both parts are enclosed in square brackets)&lt;/p&gt;
&lt;p&gt;For example: &lt;code&gt;[Me&amp;#64;Twitter][twitter]&lt;/code&gt;.  Which would result in &lt;a href="https://twitter.com/peterritchie"&gt;Me&amp;#64;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That reference can be used any number of times within markdown by referencing the reference name.&lt;/p&gt;
&lt;h3 id="images-in-markdown"&gt;Images in Markdown&lt;/h3&gt;
&lt;p&gt;An image in markdown is a special kind of link; it follows the same format as other links &lt;em&gt;except&lt;/em&gt; that it starts with an exclamation mark (!) and has an optional title-text enclosed in quotes.  For example &lt;code&gt;![alt-text](url &amp;quot;title-text&amp;quot;)&lt;/code&gt;.  Since the image is what is visible, the title text portion of the link is text shown when hovering over the image and the alternative text is used by accessibility features.&lt;/p&gt;
&lt;h2 id="data-urls"&gt;Data URLs&lt;/h2&gt;
&lt;p&gt;There exists the ability to encode content within a URL (so the URL is actually the &amp;quot;response&amp;quot; in the conventional URI request scenario).  &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs"&gt;Data URLs&lt;/a&gt; (Formally known as Data &lt;em&gt;URIs&lt;/em&gt;) use the &lt;code&gt;data:&lt;/code&gt; URI schema followed by an optional media type, an optional base64 extension (&lt;code&gt;;base64&lt;/code&gt;) followed by data (if the &lt;code&gt;base64&lt;/code&gt; extension is used the data is binary and is base-64 encoded).&lt;/p&gt;
&lt;p&gt;For example, with binary data for a red dot png a data URL may look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="images-data-urls-and-reference-style-markdown-links"&gt;Images, Data Urls, and Reference-Style Markdown Links&lt;/h3&gt;
&lt;p&gt;Data URLs may be used in markdown image links. With image markdown format and a data URL:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;![a red dot](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;... and result in: &lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==" class="img-fluid" alt="a red dot" title="The Image" /&gt;&lt;/p&gt;
&lt;p&gt;...or with title text:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;![a red dot](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg== &amp;quot;The Image&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;... and result in: &lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==" class="img-fluid" alt="a red dot" title="The Image" /&gt;&lt;/p&gt;
&lt;p&gt;Or, with a reference-style image link:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-markdown"&gt;![a red dot][red-dot]

[red-dot]: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;... and result in: &lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==" class="img-fluid" alt="a red dot" /&gt;&lt;/p&gt;
&lt;p&gt;Data URLs are a handy way to reduce the number of files involved in a page.  Like any feature, that can get ridiculous so the value comes when working with small chunks of data (like a red dot image.)&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs"&gt;Data URLs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Data_URI_scheme"&gt;Data URI Scheme (wikipedia)&lt;/a&gt;&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;a href="#data-urls"&gt;TL;DR&lt;/a&gt;⮷&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/agile-off-the-rails</id>
		<title>As a Delivery Team Member, I Want To Know if My Organization's Agile Initiative Is off the Rails</title>
		<link href="http://blog.peterritchie.com/posts/agile-off-the-rails" />
		<updated>2022-06-19T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;img src="/assets/adult-gd72730acb_1920.jpg" class="img-fluid" alt="concentration" /&gt;&lt;/p&gt;
&lt;p&gt;Image by &lt;a href="https://pixabay.com/users/pexels-2286921/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1850268"&gt;Pexels&lt;/a&gt; from &lt;a href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1850268"&gt;Pixabay&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Or, &lt;em&gt;as a delivery team member, I want to know if my organization's agile initiative is off the rails, so that I may compensate for it&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I have been an agile team member (delivery, engineering) in many organizations. There is a spirit to any defined agile process, a spirit that addresses known time-to-market and quality fallacies. Agile processes are like any good guidance; they are based on experience and techniques proven to address known problems.&lt;/p&gt;
&lt;p&gt;First, some context:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Excellence&lt;/strong&gt; is not about being perfect but about recognizing and exploiting opportunity.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;Project&lt;/strong&gt; is a temporary, planned effort to achieve a particular aim.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;Sprint&lt;/strong&gt; is a time-boxed period where a team works to deliver usable functionality to stakeholders.&lt;/p&gt;
&lt;p&gt;Goals and objectives are often &lt;strong&gt;Means Goals&lt;/strong&gt; and &lt;strong&gt;Means Objectives&lt;/strong&gt;, signifying they are a catalytic end to realize another end.&lt;/p&gt;
&lt;p&gt;Objectives that are meant to accomplish other objectives exist in a continuum of objectives called &lt;strong&gt;Cascading Objectives&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;Key Result&lt;/strong&gt; is not qualitatively measured (&amp;quot;done,&amp;quot; &amp;quot;improved,&amp;quot; etc.); they are measured quantitatively (&amp;quot;improved by 25%,&amp;quot; &amp;quot;decreased by a factor of 2,&amp;quot; etc.)&lt;/p&gt;
&lt;p&gt;Agile methodologies embody a continuum of purpose, motivation, and improvement. Purpose, motivation, and improvement are not team-specific concepts but are organization-wide constructs. This continuum is the result of the act of leadership.&lt;/p&gt;
&lt;p&gt;Over the years, I have witnessed many patterns of behavior that have resulted in failed agile delivery. Following are some common of those practices,&lt;/p&gt;
&lt;h2 id="agile-is-the-only-process"&gt;Agile Is the Only Process&lt;/h2&gt;
&lt;p&gt;Agile's raison d'être is to deliver value to the stakeholders. Agile is a project management technique; no enterprise devotes 100% of its resources to projects. An enterprise has a purpose for existing (their &lt;em&gt;why&lt;/em&gt;, the vision) and has a current means to achieve that purpose (their mission). Any effort not gauged by whether it satisfies the overall mission (and thus aligns with the purpose) can only succeed accidentally. Planning to succeed accidentally is not planning, and that sort of &amp;quot;planning&amp;quot; is a waste of time. Agile organizations put effort into addressing assumptions before planning value delivery.&lt;/p&gt;
&lt;p&gt;You know an organization is working against itself and pretending to be agile when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;100% of engineering time is devoted to &amp;quot;sprints.&amp;quot;&lt;/li&gt;
&lt;li&gt;Sprints are planned correctly 100% of the time and are never canceled due to change.&lt;/li&gt;
&lt;li&gt;A project plan does not focus on an operational outcome.&lt;/li&gt;
&lt;li&gt;Spikes are exceedingly rare.&lt;/li&gt;
&lt;li&gt;No stakeholder has communicated what they value.&lt;/li&gt;
&lt;li&gt;Stakeholders do not declare a spike's usable functionality; the delivery team declares it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="no-one-has-okr-training-or-expertise"&gt;No One Has OKR Training or Expertise&lt;/h2&gt;
&lt;p&gt;Goals and objectives are easily understood conceptually but are hard to implement in reality. One of the impetus' of OKRs is to recognize and address that. Objectives and deliverables are consequents of goals; they are the means to a larger end while still being an end in and of themselves. In isolation, objectives and deliverables are meaningless and, like any other misguided activities, detract from the purpose of accomplishing them. OKRs attempt to associate goal-oriented &lt;em&gt;key results&lt;/em&gt; with individual objectives, objectives that cascade from higher-level objectives.&lt;/p&gt;
&lt;p&gt;You know OKRs are in name only when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objectives do not cascade from higher-level objectives&lt;/li&gt;
&lt;li&gt;Key results are an action, not an event&lt;/li&gt;
&lt;li&gt;Key results are not measurable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To be honest, I've only ever seen failed implementations of OKRs--OKRs more often address perceived delivery failures rather than leadership failures. i.e., they are a management technique rather than a result of leadership.&lt;/p&gt;
&lt;h2 id="leadership-in-name-only"&gt;Leadership in Name Only&lt;/h2&gt;
&lt;p&gt;A manager creates and judges the attainment of goals (doing things right). A leader communicates and cultivates purpose and vision (doing the right things).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There are only &amp;quot;leaders&amp;quot; and no &amp;quot;managers.&amp;quot;&lt;/li&gt;
&lt;li&gt;&amp;quot;Leaders&amp;quot; that are late to every meeting.&lt;/li&gt;
&lt;li&gt;Activities are judged, not outcomes.&lt;/li&gt;
&lt;li&gt;Goals and objectives are only ever qualitative, not quantitative.&lt;/li&gt;
&lt;li&gt;Personal improvement is not a measured performance metric.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, I could go on. There are many more examples and many bad practices. I'd love to hear about what you've witnessed and your thoughts on these and other bad practices.&lt;/p&gt;
&lt;!--
## References:

https://www.forbes.com/sites/williamarruda/2016/11/15/9-differences-between-being-a-leader-and-a-manager/?sh=2432b1424609

--&gt;
</content>
		<summary>&lt;p&gt;&lt;img src="/assets/adult-gd72730acb_1920.jpg" class="img-fluid" alt="concentration"&gt;&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Environment-Variables-with-CSharp-Conditional-Compilation-Symbols</id>
		<title>Environment Variables with C# Conditional Compilation Symbols</title>
		<link href="http://blog.peterritchie.com/posts/Environment-Variables-with-CSharp-Conditional-Compilation-Symbols" />
		<updated>2019-12-12T00:00:00Z</updated>
		<content>&lt;p&gt;Have you ever thought, it would be nice to have a symbol like &lt;code&gt;PETERRIT&lt;/code&gt; that is unique to your domain account that you could use for code that YOU maybe working on but don't want to break the build?&lt;/p&gt;
&lt;p&gt;I occaisionally think I would like to do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;#if PETERRIT
   public class ViolatileExperiment()
   {
     //...
   }
#endif
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I think of this I go look at the docs or on Stackoverflow, but I never find anything that allows me to do that.&lt;/p&gt;
&lt;p&gt;I had that thought recently and poked around in the Project Settings for a few minutes to see what's going on.  Interestingly &lt;code&gt;&amp;quot;%USERNAME%&amp;quot;&lt;/code&gt; causes and error, but doesn't break the build.&lt;/p&gt;
&lt;p&gt;Damn, I thought.  But % is so... DOS, maybe they use a different delimiter.  So, I stuck in &lt;code&gt;${USERNAME}&lt;/code&gt;.  Nope.  Then I thought, wait, macros in build events have a specific format!  I entered &lt;code&gt;$(USERNAME)&lt;/code&gt; and low-and-behold &lt;strong&gt;it worked!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's a little wonky though, in the Project Settings it shows the expanded variable (&lt;code&gt;PETERRIT&lt;/code&gt;), but in the project file it shows the macro reference. (&lt;code&gt;$(USERNAME)&lt;/code&gt;).  I can see the macro reference getting overwritten from time to time.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Have you ever thought, it would be nice to have a symbol like &lt;code&gt;PETERRIT&lt;/code&gt; that is unique to your domain account that you could use for code that YOU maybe working on but don't want to break the build?&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/RESTful-Versioning</id>
		<title>RESTful Versioning</title>
		<link href="http://blog.peterritchie.com/posts/RESTful-Versioning" />
		<updated>2019-11-12T00:00:00Z</updated>
		<content>&lt;p&gt;Versioning is not new.  Versioning seems to be one of those things that people find hard to do or difficult to fully understand, especially with services and APIs.  RESTful versioning seems to be in the realm of Tabs v Spaces, but I want to detail my related observations (mostly of other's writings, but with some added color).&lt;/p&gt;
&lt;h2 id="what-is-a-version"&gt;What is a Version?&lt;/h2&gt;
&lt;p&gt;Before going further, I find defining terms so their meaning is explicit and understood. &lt;em&gt;Version&lt;/em&gt; is no exception.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;version&lt;/em&gt; recognizes a change to &lt;em&gt;something&lt;/em&gt; already established and assigns it an unique identity.  That identity serves as a moniker for &lt;em&gt;what&lt;/em&gt; changed so that when the &lt;em&gt;something&lt;/em&gt; that changed is processed, it can be differentiated from other &lt;em&gt;somethings&lt;/em&gt; of different versions.&lt;/p&gt;
&lt;h2 id="why-do-we-need-a-version"&gt;Why Do we Need a Version?&lt;/h2&gt;
&lt;p&gt;Based on what a version &lt;em&gt;is&lt;/em&gt;, it may seem easy to at least deduce &lt;em&gt;why&lt;/em&gt;.  That deduction usually &lt;em&gt;to differentiate different versions of things&lt;/em&gt;.  This is &lt;em&gt;what&lt;/em&gt; not &lt;em&gt;why&lt;/em&gt;. This is the part that many people seem to dismiss or let slip by.  In the context the knee-jerk response is &amp;quot;different version of the API&amp;quot; (API Versioning).  But, this simply restating what versioning is.  It's similar to defining &amp;quot;version&amp;quot; as&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;A version is the version of something in relation to other versions of the same thing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yeah, using the word you're defining in the definition is &lt;em&gt;helpful&lt;/em&gt;.  &amp;quot;Version&amp;quot; must provide:&lt;/p&gt;
&lt;h3 id="support-for-past-representations"&gt;Support For Past &lt;em&gt;&lt;strong&gt;Representations&lt;/strong&gt;&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The major reason versioning comes into play is because any one &lt;em&gt;representation&lt;/em&gt; of something evolves over time.  Needs change, understanding improves, technology evolves, imperfections are found, etc. and how something is stored or communicated needs to change to accommodate that evolution.&lt;/p&gt;
&lt;p&gt;&amp;quot;Requirements&amp;quot; are an obvious agent of change, and it would be easy to provide a trivial requirements example but a &lt;em&gt;fixing imperfection&lt;/em&gt; example would be more persuasive.  Humans like to be open-minded but inherently we live in our own worlds (our own mental model of the world).  Some of us are empathic and recognize parts of other worlds of the people around us. Or we know about a set of archetypes for which we can optimized interaction.  But in reality there are really 8+ billion other worlds out there and it's simply not humanly possible to know the intricacies of each.  Which means we make assumptions and trade-offs of what is acceptable to all of those other worlds.  Usually our audience isn't all 8+ billion people, so we're generally more correct than incorrect in our assumptions.  But, being incorrect is inevitable and expected. Much like we need to support many personalities, preferences, and needs; we also need to:&lt;/p&gt;
&lt;h3 id="support-multiple-representations-of-concepts"&gt;Support Multiple &lt;em&gt;Representations&lt;/em&gt; of Concepts&lt;/h3&gt;
&lt;p&gt;An example of this type of imperfection are date/time representations.  We live in our own &lt;em&gt;locus&lt;/em&gt; (which is like a personal &lt;em&gt;locale&lt;/em&gt;) and take for granted things we use or do in our locus from day-to-day, like Date/Time representations.  Local time has been working for each of us for all our lives, we take that for granted and use it in a representation without thinking.&lt;/p&gt;
&lt;p&gt;There are many things that make this problematic and error-prone.  I won't get into detail what  &lt;em&gt;all of those&lt;/em&gt; may be (a blog isn't the place for a tome like that).  The &lt;em&gt;fix&lt;/em&gt; is, of course, to use a &lt;em&gt;different representation&lt;/em&gt;. Implementing that fix and supporting existing representations of complex data means we need to be able to tell different representations of the same data from one another.&lt;/p&gt;
&lt;p&gt;This allows us to know how to translate each representation to the same in-memory structure when we (i.e. our code) encounter these representations; reinforcing that &lt;em&gt;representations&lt;/em&gt; differ from the &lt;em&gt;conceptual&lt;/em&gt; resource &lt;em&gt;and&lt;/em&gt; from the &lt;em&gt;implementation&lt;/em&gt; translation of the representation&lt;/p&gt;
&lt;p&gt;We need the ability to translate &lt;em&gt;multiple representations&lt;/em&gt; because there will be instances of differing representations &lt;em&gt;in the wild&lt;/em&gt; at a time.&lt;/p&gt;
&lt;h3 id="support-multiple-active-representation-versions"&gt;Support Multiple &lt;em&gt;Active&lt;/em&gt; Representation Versions&lt;/h3&gt;
&lt;p&gt;Increasingly we work in asynchronous environments where communication of data is off-loaded to asynchronous communication technology (like queues, topics, and even threads).  And with the drive to 100% availability this means that we perform software updates &lt;em&gt;in situ&lt;/em&gt; or without taking our systems completely off-line (or unavailable).  e.g. &lt;em&gt;indirect&lt;/em&gt; communication through a queue makes communication of the message independent of the processes. Until it reaches and is consumed by the destination, the message can be in a queue with neither process executing. This requires components to support &lt;strong&gt;at least&lt;/strong&gt; two versions of a representation &lt;em&gt;at the same time&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id="attributes-of-rest"&gt;Attributes of REST&lt;/h2&gt;
&lt;p&gt;Since we're in the context of &lt;strong&gt;Re&lt;/strong&gt;presentational &lt;strong&gt;S&lt;/strong&gt;tate &lt;strong&gt;T&lt;/strong&gt;ransfer where resource &lt;em&gt;representation&lt;/em&gt; is front-and-center as well as &lt;em&gt;state&lt;/em&gt; of that resource, the following is a review of main features of RESTful services:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;REST is not a distributed object style &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_3_1"&gt;3&lt;/a&gt; &lt;!--(5.2.1-1)--&gt;&lt;/li&gt;
&lt;li&gt;A resource identifier (URI/URN) is a reference to a particular conceptual resource, not to a particular representation of it. &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;1&lt;/a&gt; &lt;!--(5.2.1.1-4)--&gt;&lt;/li&gt;
&lt;li&gt;A representation of a resource is transfered between REST components. &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;1&lt;/a&gt; &lt;!--(5.2.1.1-4)--&gt;&lt;/li&gt;
&lt;li&gt;A resource maps to a set of entities that varies over time, not just the representation at the moment &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;2&lt;/a&gt; &lt;!--(5.2.1.1-2)--&gt;&lt;/li&gt;
&lt;li&gt;The set of entities that are mapped to a resource are considered equal (by resource identifier and/or representation). &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;2&lt;/a&gt; &lt;!--(5.2.1.1-2)--&gt;&lt;/li&gt;
&lt;li&gt;The semantics of mapping a resource to an entity distinguishes one resource from another and is constant. &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;2&lt;/a&gt; &lt;!--(5.2.1.1-2)--&gt;&lt;/li&gt;
&lt;li&gt;Representations are late-bound and based on characteristics of the request. &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;2&lt;/a&gt; &lt;!--(5.2.1.1-4)--&gt;&lt;/li&gt;
&lt;li&gt;An identifier may exist without, or before, any realized representations. &lt;a href="https://www.ics.uci.edu/%7Efielding/pubs/dissertation/rest_arch_style.htm#sec_5_2_1_1"&gt;2&lt;/a&gt; &lt;!--(5.2.1.1-2)--&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="restful-versioning-options"&gt;&lt;em&gt;RESTful&lt;/em&gt; Versioning Options&lt;/h2&gt;
&lt;p&gt;A quick review of objectives, for any given resource representation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we need to differentiate change independently from unrelated representations&lt;/li&gt;
&lt;li&gt;we need to differentiate different changes to related representations at the same time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are really only two fundamental options for &lt;em&gt;API Versioning&lt;/em&gt; (I didn't use &lt;em&gt;RESTful Versioning&lt;/em&gt; for reasons I hope will become clear):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Version moniker in the URI/URN, or&lt;/li&gt;
&lt;li&gt;Version moniker in the headers (or media-type)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="uriurn"&gt;URI/URN&lt;/h3&gt;
&lt;p&gt;In REST, a URL/URI &lt;strong&gt;only&lt;/strong&gt; identifies a resource, it is not a content-type identifier.  One reason for this is &lt;em&gt;Content Negotiation&lt;/em&gt;.  Content negotiation details that in the &lt;strong&gt;request for any particular resource&lt;/strong&gt;, the &lt;em&gt;representation&lt;/em&gt; of the resource (the response) can be negotiated through headers and responses.  That negotiation occurs through the single URL/URI.&lt;/p&gt;
&lt;p&gt;I.e. the response format does not need to be consistent per URL/URI. &lt;a href="https://tools.ietf.org/html/rfc7231#section-3.4"&gt;4&lt;/a&gt; If it's not clear, supporting multiple representations means there can be &lt;em&gt;many&lt;/em&gt; response formats for any single URI/URN.  Since we've already shown that each representation is independent of other, &lt;strong&gt;multiple versions need to be represented per URL&lt;/strong&gt;. Making something like &lt;code&gt;example.com/picture/v2&lt;/code&gt; for the SVG format meaningless. Therefore URI/URN versioning doesn't support some fundamental REST features.&lt;/p&gt;
&lt;h3 id="media-types-headers"&gt;Media Types (Headers)&lt;/h3&gt;
&lt;p&gt;Media types are monikers for a particular re presentation.  XML and Json or JPEG and PNG are examples of particular representations of the same resource.  But media types are more complex than that.
Media types can consist of a registered type (&lt;code&gt;application&lt;/code&gt;, &lt;code&gt;audio&lt;/code&gt;, &lt;code&gt;example&lt;/code&gt;, &lt;code&gt;font&lt;/code&gt;, &lt;code&gt;image&lt;/code&gt;, &lt;code&gt;message&lt;/code&gt;, &lt;code&gt;model&lt;/code&gt;, &lt;code&gt;multipart&lt;/code&gt;, &lt;code&gt;text&lt;/code&gt;, and &lt;code&gt;video&lt;/code&gt;), a subtype (the registered format in the standards tree, or a dot-delimited subtype tree), a suffix (prefixed with &lt;code&gt;+&lt;/code&gt;), and optional parameters (key/optional-value pairs prefixed with &lt;code&gt;;&lt;/code&gt;). Suffixes can be used to specify the underlying &lt;em&gt;structure&lt;/em&gt; of a type/subtype, e.g. JSON and XML.  Formats like SVG can be either textual or binary, so although being a image and SVG, simply specifying &lt;code&gt;image/svg&lt;/code&gt; is not enough to cover both of those structures. The media type for the XML format of SVG ends up being &lt;code&gt;image/svg+xml&lt;/code&gt;.  Application-specific types use the &lt;code&gt;application&lt;/code&gt; type and a subtype in the vendor tree (&lt;code&gt;vnd&lt;/code&gt;).  If a custom application format for a &lt;em&gt;person&lt;/em&gt; resource that uses XML format would have a media type of &lt;code&gt;application/vnd.person+xml&lt;/code&gt;.  If the service also supports JSON it would have another media type &lt;code&gt;application/vnd.person+json&lt;/code&gt;. &lt;code&gt;charset&lt;/code&gt; is a reserved parameter, other parameters have unique meaning defined within the type/subtype.  for example &lt;code&gt;text/html; charset=UTF-8&lt;/code&gt; and &lt;code&gt;application/vnd.person+json; version=2.0.0&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The take away is that &lt;strong&gt;media-types are independent from the endpoint&lt;/strong&gt;.&lt;/p&gt;
&lt;h1 id="wrapping-up"&gt;Wrapping Up&lt;/h1&gt;
&lt;p&gt;It may make sense to think that the resource is changing, but in reality it is the representation that changes.  The resource is abstract, like &lt;em&gt;client&lt;/em&gt;.  Changing Birth Date from local to UTC doesn't change the fact that the &lt;strong&gt;resource is still a &lt;em&gt;client&lt;/em&gt;&lt;/strong&gt;.  If the resource fundamentally changes, that's when you change the URL/URI.  But not with a version identifier, but a new &lt;em&gt;resource&lt;/em&gt;.  If something previously considered a &amp;quot;client&amp;quot; changes so is conceptually no longer a &amp;quot;client&amp;quot;, then a new URI/URN should be used (like &amp;quot;client&amp;quot; to &amp;quot;lead&amp;quot;).  &lt;em&gt;We wouldn't have different versions of clients, merely different representations of client information&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;A URI/URN is a reference to the single conceptual resource and not to a particular representation.  Since media types &lt;em&gt;are&lt;/em&gt; the data format of the representation and the same conceptual resource has representations that can change, &lt;strong&gt;media type must be used to specify different representations that a single URI/URNs supports&lt;/strong&gt;.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Versioning is not new.  Versioning seems to be one of those things that people find hard to do or difficult to fully understand, especially with services and APIs.  RESTful versioning seems to be in the realm of Tabs v Spaces, but I want to detail my related observations (mostly of other's writings, but with some added color).&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Service-Oriented-is-Declarative-Not-Imperative</id>
		<title>Service-Oriented is Declarative, not Imperative</title>
		<link href="http://blog.peterritchie.com/posts/Service-Oriented-is-Declarative-Not-Imperative" />
		<updated>2019-06-28T00:00:00Z</updated>
		<content>&lt;p&gt;In this post, I'd like to address a challenge that I've witnessed in the understanding of service-oriented and implementations of it.&lt;br /&gt;
The issue I've seen in the design approach of services and service-oriented systems.  Programmers and engineers can easily view each service as a function.  Services are perceived as being composed together within a set of functions commanding specific state changes to achieve one of a smaller set of final states.&lt;br /&gt;
This is really describing the totality of &lt;em&gt;how&lt;/em&gt; a system does what it does.  At some point, the &lt;em&gt;how&lt;/em&gt; must exist but in order to have a system that isn't one-off and can evolve by responding to change, we need the &lt;em&gt;how&lt;/em&gt; to be encapsulated from one another.&lt;br /&gt;
Composition of a system in this way is an &lt;em&gt;imperative&lt;/em&gt; model.  Ideal service-orientation works within a &lt;em&gt;declarative&lt;/em&gt; model.&lt;/p&gt;
&lt;p&gt;im·per·a·tive&lt;br /&gt;
   /əmˈperədiv/&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;uses statements that change a program's state.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;de·clar·a·tive&lt;br /&gt;
   /dəˈklerədiv/&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;denoting high-level programming languages which can be used to solve problems without requiring the programmer to specify an exact procedure to be followed&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, declarative is declaring the outcomes required and imperative is supplying the commands to change state in order to achieve the outcome required.&lt;/p&gt;
&lt;p&gt;Both are useful and both have benefits.  They're merely different.  One isn't better than the other.  But, they don't work well together.  Supplying a command to something that understands outcomes or supplying outcomes to something that expects command&lt;/p&gt;
&lt;p&gt;Service-orientation involves many things but in the context, it involves the principles of abstraction and autonomy.  Something that is self-contained and is a black box to consumers, represents a repeatable activity with a specific outcome. &lt;sup&gt;&lt;a href="https://www.opengroup.org/soa/source-book/ontologyv2/index.htm"&gt;OG1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This is different from what most programmers seem to understand, which is to provide an order list of commands or statements to change state.&lt;/p&gt;
&lt;p&gt;Patterns are a good example of this, and the iterator pattern is one of my favorites.  That pattern details that to traverse the elements of a container an iterator object should be used to start at an initial element and progress through the rest through the use of a &amp;quot;&lt;code&gt;next&lt;/code&gt;&amp;quot; method.  This allows any type of sequences, collections, etc. to be iterated over regardless of their implementation.  i.e. &lt;em&gt;give me &lt;em&gt;next&lt;/em&gt;, whatever &lt;em&gt;next&lt;/em&gt; means&lt;/em&gt;.  C# has this built into the language with iterators:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;foreach( var element in theContainer)
{
   Do.Something.With(element);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other languages/scenarios, the type of the container needs to be known and the unique way to enumerate all elements.  Typically reserved for collection/sequence structures, an array example may look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;for(int i = 0; i &amp;lt; anArray.Length; ++i)
{
   var element = theContainer[i];
   Do.Something.With(element);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-vb"&gt;For i = 1 to aList.Count
   Dim element = theContainer.Item(i)
Next i
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both of these blocks of code show &lt;em&gt;imperative&lt;/em&gt; commands: &lt;em&gt;get array element&lt;/em&gt; i or &lt;em&gt;get list element&lt;/em&gt; i.&lt;/p&gt;
&lt;p&gt;With C# and the iterator syntax, it's a better description to say &lt;em&gt;give me the outcome of each iteration of a container&lt;/em&gt;.  What the container does to iterate is encapsulated, the container is a black box to the caller.  We can use it the same if that container implementation used an array, a list, or just had hard-coded values.&lt;/p&gt;
&lt;p&gt;Services in Service-Orientation should take this form.  A service is a location where an outcome can be retrieved, usually with parameters.  Thinking in this way allows us to think of the outcomes we want to work with, rather than the details of how those outcomes are produced.  I allow us to (and is recommended) to think about things in our problem domain (or higher-level abstractions).  If we're thinking about a conference, we can think of a session as a container of registered attendees.  I can then model that I want to perform an activity with the information from each registered attendee before I implement something and decide &lt;em&gt;how&lt;/em&gt; that will be implemented.&lt;/p&gt;
&lt;p&gt;In a service, we should not have a contract that details &lt;em&gt;how&lt;/em&gt; an activity should be performed. A service contract should only detail the outcome and what parameters are required to get that outcome.&lt;/p&gt;
&lt;p&gt;Almost all design patterns (that aren't structural patterns) effectively do this: to abstract away implementation details in favor of declaring the outcome desired.  &amp;quot;Declarative&amp;quot; can also be considered &amp;quot;composable&amp;quot;: you're declaring how to compose things rather than the flow of logic.  The messaging library I published, you can effectively declare a producer, a consumer, and a channel/pipe between them.  Once composed like that, the type of channel/pipe used hides how the messages move between the producer and the consumer (in-memory, queue, HTTP endpoint, etc.).  You don't have imperatively create a queue (or a topic, etc) and imperatively connect the consumer and producer to the queue.&lt;/p&gt;
&lt;p&gt;I realize this is very subtle and, in particular, the iterator example. And maybe some advice on naming may help to bring it over the line. What also makes these concepts complex is that they're not digital; i.e. nothing is entirely declarative or entirely imperative, there are degrees of declartiveness/imperativeness.&lt;/p&gt;
&lt;p&gt;Service names should generally be nouns (e.g. the name of the &amp;quot;outcome&amp;quot; of the activity).  REST describes these as resources, which should also be nouns.  Verbs and a dead giveaway that something is imperative (if that wasn't obvious by the use of &lt;em&gt;imperative&lt;/em&gt; :) ).  Inputs in contracts should not contain verbs as well, consider the input/output as resources.&lt;/p&gt;
&lt;p&gt;Additionally, this doesn't mean everything using the outcomes of declarative statements must be declarative.  You can certainly program a set of statements to change state based on what that outcome was.&lt;/p&gt;
&lt;h3 id="traits-and-smells"&gt;Traits and Smells&lt;/h3&gt;
&lt;p&gt;One of the traits of services that are not imperative is that they can be viewed as stateless.  If the need arises to store per-session state or state that shouldn't be available to other consumers of the service, that's a smell to tell you that you're probably more imperative than declarative.  The solution to this is to ensure anything required for the activity to be performed should be supplied in the input.  REST services facilitate this through HATEOS.  There was &lt;em&gt;state&lt;/em&gt; when an activity was requested, and it should be passed back in one or more hyperlinks for stateless services.  e.g. The current total number of resources at an endpoint at that point in time.  You may be paging through resources a page at a time and something could change between requests.  To avoid problems with that the state is effectively &lt;em&gt;stored&lt;/em&gt; in the response via links.  At the time of a request, a service may have 20 resources, if paging 10 at a time the &amp;quot;next&amp;quot; page for page one would be 2. If something changed before page 2 was retrieved, the response for page 2 may include page 3 for &amp;quot;next&amp;quot;.&lt;/p&gt;
&lt;p&gt;Next time, I'll talk about how &amp;quot;declarative&amp;quot; doesn't mean always up front.&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.opengroup.org/soa/source-book/ontologyv2/index.htm"&gt;Service-Oriented Architecture Ontology Version 2.0 - The Open Group&lt;/a&gt;&lt;/p&gt;
</content>
		<summary>&lt;p&gt;In this post, I'd like to address a challenge that I've witnessed in the understanding of service-oriented and implementations of it.&lt;br&gt;
The issue I've seen in the design approach of services and service-oriented systems.  Programmers and engineers can easily view each service as a function.  Services are perceived as being composed together within a set of functions commanding specific state changes to achieve one of a smaller set of final states.&lt;br&gt;
This is really describing the totality of &lt;em&gt;how&lt;/em&gt; a system does what it does.  At some point, the &lt;em&gt;how&lt;/em&gt; must exist but in order to have a system that isn't one-off and can evolve by responding to change, we need the &lt;em&gt;how&lt;/em&gt; to be encapsulated from one another.&lt;br&gt;
Composition of a system in this way is an &lt;em&gt;imperative&lt;/em&gt; model.  Ideal service-orientation works within a &lt;em&gt;declarative&lt;/em&gt; model.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Thoughts-Web-Services--REST-APIs--and-Message-Structure</id>
		<title>Thoughts on Web Services, REST APIs, and Message Structure</title>
		<link href="http://blog.peterritchie.com/posts/Thoughts-Web-Services--REST-APIs--and-Message-Structure" />
		<updated>2019-04-09T00:00:00Z</updated>
		<content>&lt;h2 id="part-1-http"&gt;Part 1: HTTP&lt;/h2&gt;
&lt;p&gt;Love it or hate it, HTTP is ubiquitous.  It's been around for thirty years.
It has evolved alot in those thirty years.  One critical way it has evolved is
to support flexibility. Despite the huge benefits of that flexibility it can
and has lead people away from recommended and expected usage and patterns.&lt;/p&gt;
&lt;p&gt;&amp;quot;No big deal&amp;quot;, some say, but being lead away from recommended
usage leads to re-discovery and re-invention and an evolutionary way of
working (i.e. it's never right the first time).  This evolutionary process
is a constraining process, each step must be based on the last and all that
came before it.  That's great when you do have to invent something that never
existed; but when a solution already exists, this process needlessly
constrains progress sometimes to the point of missing the actual
recommendation or expectation.&lt;/p&gt;
&lt;p&gt;The flexibility of HTTP really means that people have to have a deep or broad
knowledge of it to use it properly.  Take the &lt;code&gt;Accept&lt;/code&gt; request header and
media types. It allows a requestor to limit and rank the possible content
format. We typically see this with at least XML and JSON nowadays.  To be
clear this means Web APIs can have different formats of responses. The
Content-Type header field means the inverse, that an API can accept multiple
request content formats.  As flexible as this is, different content formats
have at least some lack of parity of features.  As an example, XML has rich
syntax that includes things like full featured consistent schema definitions.
JSON is working towards things like that, but this is an example where the
two have different semantic structure.  There are things that can be done to
compensate, but at the end of the day neither was designed to work exactly like
the other (that's kinda the point, isn't it?)  This is just one example where
there's possibility of mismatch, mismatch in how two content formats can
represent the same thing.&lt;/p&gt;
&lt;p&gt;You may be thinking, &lt;em&gt;where am I going this with&lt;/em&gt;?  Thanks for the segue. What
this means is there will be times when you &lt;em&gt;change the structure or schema&lt;/em&gt; of
content (request or response) &lt;strong&gt;because it's one type OR the other&lt;/strong&gt;.  Which
leads me back towards media types.  If the schema of a JSON response
changes but the XML doesn't, what does &lt;em&gt;versioning&lt;/em&gt; of APIs mean?  Well, it
means that because there are different formats of content is independently
changing schemas &lt;strong&gt;you cannot reliably the version an API by URI&lt;/strong&gt;.  You can't even use a general
header field that applies to all content because a change to one could be
breaking but unnecessary or non-breaking in the other.  Making versioning
problematic at best.  This means you really &lt;strong&gt;must use media type as the
versioning mechanism&lt;/strong&gt;. (&amp;quot;MTATEOV&amp;quot;: Media Type As The Engine of
Versionability?)&lt;/p&gt;
&lt;p&gt;But, if you've ignored media types and effectively ignored schemas and cause
breaking changes because it just works and breaking changes have been
tolerable.  Of course, being in this situation and let the flexibility
herd you into this corner.  But, it really is fairly easy also ends up
solving these issues as well as open up some opportunities like Web Linking to
content type and version! Let's have a look at the standard format of the media type.&lt;/p&gt;
&lt;p&gt;Media types consist of a &lt;em&gt;type&lt;/em&gt; and a &lt;em&gt;subtype&lt;/em&gt;, separated by a forward slash.&lt;br /&gt;
For example &amp;quot;application/xml&amp;quot;, &amp;quot;application/json&amp;quot;.  The subtype is further
structured in a tree that provides many options.  There are standards subtypes
that are fixed or *standard&amp;quot; like &amp;quot;text/html&amp;quot; and &amp;quot;image/png&amp;quot; which specify a
standard format.  The standards subtypes typically fall under types like
&amp;quot;text&amp;quot;, &amp;quot;image&amp;quot;, etc.&lt;/p&gt;
&lt;p&gt;There can be application-specific subtypes and those fall under the
&amp;quot;application&amp;quot; type.  There is a bit of inconsistency in media types, like
JSON is &amp;quot;application/json&amp;quot; and XML is &amp;quot;text/xml&amp;quot; despite the two content
formats having standard structure and semantics.  But, I'll focus on
application-specific structures because you should only need to version
application-specific structures.&lt;/p&gt;
&lt;p&gt;Despite application-specific, the application-specific parts can be built off
of those standard content structures like XML and JSON to create a custom
subset schema (so to speak).  Media type standard supports that including a
suffix and parameters to the subtype.  The subtype format is essentially
&lt;code&gt;subtype[&amp;quot;+&amp;quot; suffix] [*&amp;quot;;&amp;quot; parameter]&lt;/code&gt; or &amp;quot;subtype&amp;quot; followed by an optional
suffix separated by &amp;quot;+&amp;quot; followed by one or more parameters separated by &amp;quot;;&amp;quot;.&lt;br /&gt;
And each parameter may have an optional value separated by &amp;quot;=&amp;quot;.
So, I could specify that I have HTML text encoding as UTF-8 as
&amp;quot;text/html; charset=UTF-8&amp;quot; or I could specific an application-specific format
(like &amp;quot;gibberish&amp;quot;) that is based on XML like this &amp;quot;application/gibberish+xml&amp;quot;.&lt;/p&gt;
&lt;p&gt;In order to avoid name clashes with other vendors, these media types are
expected to be in the Vendor Tree where standards types fall under the root or
Standards Tree.  Trees are specified with a prefix to the subtype, making
the standard structure of a subtype like this
&lt;code&gt;[tree &amp;quot;.&amp;quot;] subtype[&amp;quot;+&amp;quot; suffix] [*&amp;quot;;&amp;quot; parameter]&lt;/code&gt;.  &lt;em&gt;tree&lt;/em&gt; as the
structure of &lt;code&gt;tree *[&amp;quot;.&amp;quot; subtree]&lt;/code&gt; meaning there can be many trees separated
by &amp;quot;.&amp;quot;.  The standard details that the Vendor Tree starts with the &amp;quot;vnd.&amp;quot;
prefix.  So, our custom type should really have the form
&amp;quot;application/vnd.pri.gibberish+xml&amp;quot;, where &amp;quot;pri&amp;quot; is a vendor-specific name or
identifier.  Or if JSON format is required: &amp;quot;application/vnd.pri.gibberish+xml&amp;quot;.&lt;/p&gt;
&lt;p&gt;Now that we know about custom, vendor application-specific type identifiers,
on to dealing with changes to that content format that may introduce breaking
changes, or &lt;em&gt;versioning&lt;/em&gt;.  Since we're dealing with vendor and application-
specific identifiers within &lt;em&gt;subtype&lt;/em&gt; we deviate into an area not covered
specifically by a standard.  And you're basically free to do anything you want
to specify the version, some have a format like
&amp;quot;application/vnd.pri.gibberish.v2+xml&amp;quot;.  Some use a subtype parameter like
&amp;quot;application/vnd.pri.gibberish+xml;v=2&amp;quot; or
&amp;quot;application/vnd.pri.gibberish+xml;version=2&amp;quot;.  Since what lead us on
this particular journey was the problem of diverging versions between
underlying structures, the parameter route makes more sense because the
version really applies, in that case, to the content with an underlying
structure.  And being a parameter after the prefix, it's less like a version
of the subtype. e.g. &amp;quot;application/vnd.pri.gibberish.v2+xml&amp;quot; could be
interpreted as gibberish version 2 with an underlying XML structure.  But
&amp;quot;application/vnd.pri.gibberish+xml;v=2&amp;quot; is easier to interpret as
gibberish+xml version 2.&lt;/p&gt;
&lt;p&gt;Side note: In the versions I've shown here I've not used a minor version
(like 2.1).  I did that on purpose based on SEMVER that stipulates major
version number increment to signify breaking changes.  Non-breaking changes
in content is achieved with optional values, so client requestors that
don't know the new optional values won't use them and thus minor version
doesn't matter.  Also, if new optional values appear in a response, the
requester shouldn't care either.  You can structure your schema to make such
that a requestor need to care about it, but that is a breaking change and a
major version increment, not a minor version increment.&lt;!-- 2019, April--&gt;&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Love it or hate it, HTTP is ubiquitous.  It's been around for thirty years.
It has evolved alot in those thirty years.  One critical way it has evolved is
to support flexibility. Despite the huge benefits of that flexibility it can
and has lead people away from recommended and expected usage and patterns.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<id>http://blog.peterritchie.com/posts/Domain-Oriented-Observability-The-Decorative-Way</id>
		<title>Domain-Oriented Observability: The Decorative Way</title>
		<link href="http://blog.peterritchie.com/posts/Domain-Oriented-Observability-The-Decorative-Way" />
		<updated>2019-04-02T00:00:00Z</updated>
		<content>&lt;p&gt;I read an interesting article by Pete Hodgson on Martin Fowler's blog/site titled &lt;a href="https://martinfowler.com/articles/domain-oriented-observability.html"&gt;Domain-Oriented Observability&lt;/a&gt;.  In this article, Pete suggests separating the responsibility of observability out of a domain class that might initially look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-java"&gt;  applyDiscountCode(discountCode){
    this.logger.log(&amp;quot;attempting to apply discount code: ${discountCode}&amp;quot;);

    let discount; 
    try {
      discount = this.discountService.lookupDiscount(discountCode);
    } catch (error) {
      this.logger.error(&amp;quot;discount lookup failed&amp;quot;,error);
      this.metrics.increment(
        &amp;quot;discount-lookup-failure&amp;quot;,
        {code:discountCode});
      return 0;
    }
    this.metrics.increment(
      &amp;quot;discount-lookup-success&amp;quot;,
      {code:discountCode});

    const amountDiscounted = discount.applyToCart(this);

    this.logger.log(&amp;quot;Discount applied, of amount: ${amountDiscounted}&amp;quot;);
    this.analytics.track(&amp;quot;Discount Code Applied&amp;quot;,{
      code:discount.code, 
      discount:discount.amount, 
      amountDiscounted:amountDiscounted
    });

    return amountDiscounted;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;...into something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-java"&gt;  applyDiscountCode(discountCode){
    this.instrumentation.applyingDiscountCode(discountCode);

    let discount; 
    try {
      discount = this.discountService.lookupDiscount(discountCode);
    } catch (error) {
      this.instrumentation.discountCodeLookupFailed(discountCode,error);
      return 0;
    }
    this.instrumentation.discountCodeLookupSucceeded(discountCode);

    const amountDiscounted = discount.applyToCart(this);
    this.instrumention.discountApplied(discount,amountDiscounted);/*sic*/
    return amountDiscounted;
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I applaud the effort to put the responsibility of observability of the applying discounts into a singly-responsible class.  But, the domain-oriented class is still burdened with the responsibility of observability even if it simply delegates to another class.  It's now &lt;em&gt;also&lt;/em&gt; responsible for knowing about another class/interface, and possibly responsible for instantiating it.&lt;/p&gt;
&lt;p&gt;In my mind, this &lt;em&gt;is&lt;/em&gt; better, but really just trades some responsibilities for others.  And if the shopping cart is composed and the instrumentation class abstracted by an interface this &lt;strong&gt;minimizes&lt;/strong&gt; those responsibilities,  but they're still &lt;em&gt;in&lt;/em&gt; the shopping cart.&lt;/p&gt;
&lt;p&gt;When working with team members, my recommendation is to choose composability over mixing responsibilities or concerns in cases like this.  You can do this through the use of the &lt;a href="https://en.wikipedia.org/wiki/Decorator_pattern"&gt;Decorator Pattern&lt;/a&gt;.  For example, if we create a decorating shopping cart that passes through to a production shopping cart, we can &amp;quot;inject&amp;quot; the observability into the use of that production shopping cart without having to clutter up the domain-oriented class (after all, the point was &lt;em&gt;cleaning up the mess&lt;/em&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;class InstrumentingShoppingCart : IShoppingCart
{
	private readonly IShoppingCart component;
	private readonly DiscountInstrumentation instrumentation;


	public InstrumentingShoppingCart(IShoppingCart component, DiscountInstrumentation instrumentation)
	{
		this.component = component;
		this.instrumentation = instrumentation;
	}

	public float applyDiscountCode(int discountCode)
	{
		this.instrumentation.applyingDiscountCode(discountCode);
		try
		{
			var discountAmount = component.applyDiscountCode(discountCode);
			this.instrumentation.discountCodeLookupSucceeded(discountCode);
			this.instrumentation.discountApplied(discountAmount);
			return discountAmount;
		}
		catch (Exception error)
		{
			this.instrumentation.discountCodeLookupFailed(discountCode, error);
			return 0;
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An &lt;code&gt;InstrumentingShoppingCart&lt;/code&gt; instance can be used where any &lt;code&gt;IShoppingCart&lt;/code&gt; is used and can be composed in whatever fashion is necessary (IoC container, Composition Root, etc.).&lt;/p&gt;
&lt;p&gt;Now we get instrumentation, instrumentation as a responsibility is separated, &lt;em&gt;and&lt;/em&gt; the domain-oriented class is not messed up with other concerns and responsibilities.  For example, the original unincumbered method:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-Java"&gt;  applyDiscountCode(discountCode){

    let discount; 
    discount = this.discountService.lookupDiscount(discountCode);

    const amountDiscounted = discount.applyToCart(this);
    return amountDiscounted;
  }
&lt;/code&gt;&lt;/pre&gt;
</content>
		<summary>&lt;p&gt;I read an interesting article by Pete Hodgson on Martin Fowler's blog/site titled &lt;a href="https://martinfowler.com/articles/domain-oriented-observability.html"&gt;Domain-Oriented Observability&lt;/a&gt;.  In this article, Pete suggests separating the responsibility of observability out of a domain class that might initially look like this:&lt;/p&gt;</summary>
	</entry>
</feed>